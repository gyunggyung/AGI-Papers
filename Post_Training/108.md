---
id: 108
category: Post_Training
title: When Reasoning Meets its Laws
---
When Reasoning Meets its Laws

지금 우리가 쓰는 Gemini 3 Pro나 GPT-5.2는 `2+3`을 물어보면 과거보다는 빠르게 대답합니다. 하지만 불과 1년 전만 해도 상황은 코미디에 가까웠습니다. 당시 화제였던 초기 모델들(DeepSeek-R1, o1)에게 "Strawberry(딸기)에 r이 몇 개야?"라고 물으면, AI는 2분 동안 수천 단어의 독백을 쏟아내며 글자를 분해하고 재조립하다가... 결국 "2개"라고 틀리곤 했죠. 심지어 "2+3=?" 같은 산수 문제에 논문을 쓰듯 과몰입하다 오답을 내는 현상을 비판한 논문(Do NOT Think That Much for 2+3=?)이 나올 정도였습니다.

왜 그 시절의 AI는 쉬운 문제엔 집착하고, 어려운 문제는 대충 넘겨짚는 '비일관성의 늪'에 빠졌던 걸까요?

오늘 소개할 논문 "When Reasoning Meets its Laws (LORE)"는 이 AI의 뇌 구조에 '추론의 물리 법칙'을 심어, 비로소 "효율적으로 생각하는 법"을 가르친 흥미로운 연구입니다.

1. 1년 전의 미스터리: "왜 더 어려운 문제를 더 빨리 풀지?"

연구진은 당시 SOTA 모델들을 해부하며 충격적인 사실을 발견합니다. 모델들이 "문제를 합치면(Composition), 생각의 양도 합쳐져야 한다"는 상식을 밥 먹듯이 어기고 있었던 거죠.

 - Case Study: DeepSeek-R1 (Distill 1.5B)의 기행
 - Q1 (단일 문제): "55를 제곱해." → 생각: 1,197 토큰 (매우 신중함)
 - Q2 (복합 문제): "1부터 10까지 더하고, 55를 제곱해." → 생각: 817 토큰 (???)

더 복잡한 문제를 줬는데 오히려 생각을 300토큰이나 덜 하고, 결과적으로 정답률은 12.5%p(포인트)나 폭락했습니다. 마치 수능 수학 킬러 문항을 3초 만에 찍고 자버리는 것과 같습니다.

이런 현상을 바로잡기 위해 연구진은 두 가지 '추론의 법칙(Laws of Reasoning)'을 선포합니다.

2. 추론을 지배하는 두 가지 절대 법칙

① 제1법칙: 연산의 법칙 (Compute Law)

> "Compute ∝ Complexity"
> 생각의 양은 문제의 복잡도에 정비례해야 합니다. 쉬운 건 짧게, 어려운 건 길게. 이 당연한 비례식을 깨는 순간 AI는 '멍청한 과몰입'을 시작합니다.

② 제2법칙: 정확도의 법칙 (Accuracy Law)

> "Accuracy = exp(-Complexity)"
> 복잡도가 오르면 성공 확률은 지수적으로 떨어집니다. 이를 인정하고 예측 가능한 범위 내에서 움직여야 환각(Hallucination)을 막을 수 있습니다.

3. 단 3,900개의 데이터가 만든 기적: "트리플렛(Triplet)의 비밀"

이 논문의 백미는 해결책입니다. 수조 개의 데이터를 때려 붓는 '물량 공세'가 아니었습니다. 연구진은 단 3,900개의 데이터만 사용했습니다.

많은 분들이 "데이터가 3,900개면 너무 적은 거 아니냐?"고 묻습니다. 하지만 이 데이터는 단순한 Q&A가 아닙니다. 연구진은 [문제 A], [문제 B], [문제 A+B]를 한 세트로 묶은 '트리플렛(Triplet)' 구조를 설계했습니다.

 - 기존 학습: A를 풀고, B를 푼다. (끝) → A+B가 나오면 AI는 당황해서 대충 풉니다.
 - LORE의 학습 (SFT-Compo):
 1. Task A: "55의 제곱을 구해라." (과정: 5단계 추론)
 2. Task B: "1~10의 합을 구해라." (과정: 3단계 추론)
 3. Task A+B: "1~10의 합을 구하고 55를 제곱해라."

 - 핵심: 이때 정답 데이터는 개별 문제 풀이의 합(5+3)과 결합 문제 풀이(8)의 길이가 일치하도록 정제된 데이터만 학습시킵니다. 즉, 논리적 호흡을 맞추도록 강제하는 것이죠.

즉, 모델에게 정답을 알려주는 게 아니라 "쉬운 문제(B)와 어려운 문제(A)가 섞여 있을 때, 에너지를 어떻게 배분해야 하는지" 그 구조적 감각(Compositionality)을 가르친 것입니다. 마치 운동선수에게 "100m 달리기와 마라톤을 연달아 할 때는, 각각의 페이스를 유지해서 합산한 기록이 나와야 한다"고 페이스 조절을 가르친 것과 같습니다.

최신 GPU로 돌리면 커피 한 잔 마실 시간이면 끝나는 5 Epoch, 1,200 Step의 가벼운 학습. 하지만 결과는 마법 같았습니다.

4. 결과: "요령 있는 천재"의 탄생

 - 논리적 일관성 회복: 모델이 제멋대로 생각하던 오차율(nMAD)이 0.528 → 0.314로 40% 급감했습니다. 더 이상 쉬운 문제에 과몰입하지 않습니다.
 - 성능 폭발: 단순히 말을 잘 듣는 게 아니라 똑똑해졌습니다. DeepSeek-R1-8B 모델은 MATH500 점수가 76.4% → 83.0%로 (+6.6%p) 수직 상승했습니다.
 - 시너지 효과: 연산 법칙만 가르쳤는데, 정확도의 예측 가능성까지 71%나 개선되었습니다.

💡 마치며: "생각은 양(Quantity)이 아니라 구조(Structure)다"

LORE 논문은 2025년 AI 발전사의 중요한 변곡점을 다룹니다. 무작정 "오래 생각하라(CoT)"고 강요했던 초기 모델들의 한계를 넘어, "문제의 구조에 맞춰 유연하게 사고하라"는 패러다임을 제시했기 때문입니다.

오늘날 우리가 쓰는 Gemini 3 Pro가 쉬운 문제는 순식간에 직관으로, 어려운 문제는 깊이 있게 처리하는 그 '유연함'의 기원이 바로 여기에 있습니다. (물론 아직 부족합니다)

결국 AI나 사람이나 똑같습니다. 무작정 책상에 오래 앉아 있는다고 공부 잘하는 게 아니듯, AI도 '생각의 구조'가 잡혀야 비로소 천재가 됩니다.
