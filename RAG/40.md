---
id: 40
category: RAG
title: 왜 모델은 학습이 끝나면 더 이상 똑똑해지지 않는가?
---
왜 모델은 학습이 끝나면 더 이상 똑똑해지지 않는가?

2017년, 트랜스포머가 세상에 나오고 9년이 지났습니다. 이제는 2026년입니다. 우리는 여전히 RAG 파이프라인을 깎고 있고, 컨텍스트 윈도우를 100만, 1000만 토큰으로 늘리는 무한 경쟁을 지켜보고 있습니다. 그런데 뭔가 이상하지 않나요?

지금까지 우리는 LLM을 '냉동 인간(Frozen)' 취급했습니다.

모델은 거대한 도서관(RAG)에 가서 책을 잠시 빌려볼 뿐, 책을 덮으면(Context가 끝나면) 그 지식은 연기처럼 사라집니다. 기억하는 게 아니라, 잠시 참조할 뿐이었으니까요.

하지만 학계의 최전선에서는 이 고정관념이 바뀌고 있습니다. 책을 읽으며 스스로의 뇌 구조를 실시간으로 뜯어고치는(Adaptation) 모델들이 등장했기 때문입니다.

올해에는 실행하면서 배우는 상용 모델이 등장할 것입니다. 그 확신을 주는 핵심 재료 7가지(TTT, ATLAS, SEAL, Mem0, Titans, Mamba, Reflexion)를 모아 "적응(Adaptation)의 5단계"로 정리했습니다.

이 연구들이 가리키는 미래는 하나입니다. 

"기억은 저장이 아니라, 변화다."


[프레임워크] 모델은 추론 중에 무엇을 바꾸는가?

우리는 그동안 모델을 고정된 함수로만 여겼습니다. 하지만 최신 연구들은 추론 시점에 모델의 특정 부분을 실시간으로 변화시키려 합니다. "어디를 건드리는가(Target)"에 따라 기술의 레벨이 나뉩니다.

1. 언어적 문맥 (Context): "포스트잇을 붙인다"

가장 기초적인 단계입니다. 모델 파라미터는 건드리지 않고, 모델이 볼 수 있는 메모를 남깁니다.

 - Reflexion 
모델의 뇌 용량을 믿지 못해 외장 하드& Self-Refine: 모델이 틀리면 "왜 틀렸는지" 스스로 반성문(Feedback)을 씁니다. 다음 추론 때 이 반성문을 문맥(Context)에 포함시켜 행동을 교정합니다. 쉽고 직관적이지만, 문맥 길이가 늘어나는 비용이 발생합니다.

2. 외부 저장소 (External DB): "도서관에 책을 꽂는다"
를 붙이는 방식입니다.

 - Mem0 & RAG: 단순히 텍스트를 저장하는 것을 넘어, 지식 그래프(Graph Memory)로 사용자 취향이나 장기 기억을 관리합니다. 가장 안전하고 영구적이지만, 모델 자체의 지능(IQ)이 높아지는 것은 아닙니다.

3. 내부 상태 (Hidden State): "요약본을 최적화한다"


 - ATLAS (Google): RNN 구조의 한계였던 기억 용량을 수학적으로 뚫어버렸습니다. 'Omega Rule'과 'Muon Optimizer'라는 새로운 알고리즘을 통해, 1,000만 토큰을 처리하면서도 중요한 정보를 잊지 않고 내부 상태 메모리(M_t)에 각인시킵니다.
 - Mamba & SSMs: 기존 트랜스포머처럼 모든 정보를 펼쳐놓는 게 아니라, 입력에 따라 정보를 선별적으로 압축하여 상태를 갱신합니다.


4. 전용 메모리 모듈 (Neural Memory): "보조 노트를 쓴다"

모델 본체는 건드리기 무서우니, 기억만을 담당하는 별도의 작은 신경망을 만듭니다.


5. 모델 가중치 (Weights): "뇌세포를 재배열한다"

가장 급진적이고 강력한 접근입니다. 추론하는 과정 자체를 학습으로 보고, 본체의 시냅스(파라미터)를 직접 바꿉니다. 역전파(Backprop)를 통해 지능 자체를 재구성합니다. 이 단계는 다시 수동적 적응과 능동적 적응으로 나뉩니다.

 - Type A. 구조적 적응 (TTT-E2E): "기계적으로 압축한다"
 - 의의: 책을 수천 권 읽어도 메모리가 터지지 않고 추론 속도가 일정(Constant Latency)하게 유지됩니다. 효율성의 혁명입니다.

 - Type B. 에이전트적 적응 (SEAL): "스스로 학습한다"
 - MIT는 한발 더 나아갔습니다. 모델이 입력값을 보고 "이걸 풀려면 내가 뭘 더 배워야 하지?"를 판단합니다.
 - 스스로 학습 데이터(Self-Edit)를 생성하고, 그 데이터로 자기 자신을 미세조정(SFT)합니다. 누가 시키지 않아도 스스로 부족한 점을 보완하는 진정한 의미의 '독학(Self-Taught)' 모델입니다.


💡 결론: Read-Only에서 Re-Write로

지금까지의 AI 트렌드가 RAG나 Reflexion 같은 '외부/문맥적 접근'이었다면, 2026년의 트렌드는 TTT, ATLAS, SEAL 같은 '모델 내부/파라미터적 접근'으로 깊숙이 이동하고 있습니다.

모델이 단순히 정보를 참조(Read)하는 것을 넘어, 경험을 통해 스스로를 미세하게 재설계(Re-Write)하는 단계로 진입했습니다.

재료는 다 모였습니다. 이제 이 재료들을 하나의 상용 모델로 요리해 낼 차례입니다. 그게 바로 올해 우리가 목격할 Next GPT의 모습일 것입니다.



88




