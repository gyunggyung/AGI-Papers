---
id: 82
category: Projects
title: LFM2 번역기 개발기: 핵심 발견 및 성과
---
# LFM2 번역기 개발기: 핵심 발견 및 성과

**👉 핵심 발견:**
SFT 데이터 200k로 베이스를 다진 후, 고품질 80k 데이터로 Curriculum Learning을 진행했더니, GRPO 강화학습을 적용한 모델과 단 0.48점 차이까지 좁혔습니다.

다시 말해, 데이터 품질에 집중한 SFT만으로도 RL 모델에 근접한 성능을 낼 수 있음을 확인했습니다.

## 🔧 현재 진행 중인 작업

Maxime Labonne님의 조언을 따라 약점 보완을 위한 DPO(Direct Preference Optimization)를 준비 중입니다.

**📋 모델이 아직 잘 못하는 것들:**
*   **관용구:** "Piece of cake" → "케이크 조각" (X) → "식은 죽 먹기" (O)
*   **긴 문장:** 20단어 이상 복잡한 문장에서 맥락을 놓침
*   **외국 인명:** "Brzezinski" 같은 이름을 일관되게 음역하지 못함
*   **고객 서비스 표현:** 일상 대화체 번역이 딱딱함

이 약점들을 보완하기 위해 DPO 데이터셋 10,068쌍을 구축했습니다. 현재 Colab에서 DPO 학습 데이터 생성 중이며, 시간이 좀 걸릴 예정입니다. DPO 이후에는 GRPO 강화학습을 다시 적용할 계획입니다.

## 📚 공식 Cookbook 등록!

Pau Labarta Bajo님이 제 v5-RL 모델을 Liquid AI 공식 Cookbook에 추가해 주셨습니다. 이제 더 쉽게 모델을 테스트하고 활용해보실 수 있습니다.

## 💡 향후 아이디어: 새로운 벤치마크?

현재 CHrF++/BLEU 같은 기존 벤치마크에는 한국어 존댓말/반말을 구분하지 못하는 한계가 있습니다.

예를 들어:
*   Reference: "이것 좀 확인해 주세요." (존대)
*   Hypothesis: "이거 확인해." (반말)
→ 의미는 같지만 점수가 크게 하락

이 문제를 해결하는 Multi-Reference 벤치마크(존댓말/반말 각각 정답으로 인정)를 구축하면 논문감이 될 것 같습니다. 학습이 마무리되면 본격적으로 연구해볼 생각입니다.
