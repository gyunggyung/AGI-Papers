---
id: 43
category: RAG
title: 말도 많고 탈도 많았던 국가대표 AI 프로젝트의 1차 윤곽이 잡혔습니다. 결과적으로 LG AI Research, SK Telecom, Upstage가 선발되었고, 네이버클라우드(NAVER Cloud)와 NC AI는 탈락했습니다. 그리고 탈락한 두 기업은 패자부활전에 참여하지 않기로 했습니다.
---
말도 많고 탈도 많았던 국가대표 AI 프로젝트의 1차 윤곽이 잡혔습니다. 결과적으로 LG AI Research, SK Telecom, Upstage가 선발되었고, 네이버클라우드(NAVER Cloud)와 NC AI는 탈락했습니다. 그리고 탈락한 두 기업은 패자부활전에 참여하지 않기로 했습니다.

지난번 제가 쓴 분석 글을 Hugging Face CEO인 Clem Delangue 🤗가 퍼가며 화제가 되기도 했는데요. 글로벌이 주목할 만큼 우리 기업들이 치열하게 경쟁했고, 정부의 막대한 예산과 GPU 지원이 있었기에 이 정도 수준의 모델들이 나올 수 있었다고 생각합니다.

다만, 이번 결과표에 대해 두 가지 생각이 듭니다.

1. SKT A.X: 명실상부한 국대, 그리고 "진짜 오픈소스"
먼저 SKT에 박수를 보냅니다. 이번 경쟁의 진정한 승자는 SKT라고 봅니다.

✅ Apache 2.0의 품격
SKT는 성능(DeepSeek AI V3.1보다 높은 코딩/수학 점수)을 잡았을 뿐만 아니라, Apache 2.0 라이선스를 채택했습니다. 이는 MIT 라이선스와 더불어 개발자가 가장 사랑하는 진짜 오픈소스(OSI Approved) 라이선스입니다.

성능 좋은 모델을 제한 없이 풀었다는 점에서 SKT는 국가대표 자격이 차고 넘칩니다. 개발자들에게는 지금 당장 쓸 수 있는 최고의 선택지입니다.

2. NCSOFT (VAETKI): 탈락하기엔 너무나 아까운 '투명성'
그럼에도 불구하고 NC의 탈락이 뼈아픈 이유는 그들이 보여준 투명성과 실용성 때문입니다.

✅ MIT 라이선스와 데이터의 완전 공개
NC는 국내 모델 중 유일하게 MIT 라이선스를 달고 나왔습니다. 심지어 학습에 사용한 9.8T(약 10조) 토큰의 출처(FineWeb, The Stack v2 등)를 명확히 밝혔습니다. 기업 입장에서 쉽지 않은 결정이었을 텐데 말이죠.

✅ 효율을 증명한 MoE
NC의 VAETKI는 총 112B 파라미터 중 활성 파라미터가 10B에 불과한 MoE 구조입니다. 추론 효율을 극대화한 구조죠.

✅ 수학은 아쉽지만, 일머리는 최고
냉정하게 말해서 복잡한 추론(GPQA, HLE) 점수는 경쟁사 대비 낮습니다. 하지만 실전 능력은 탁월합니다.
- 지시 이행(IFEval): 86.0점 (gpt-oss-120b 상회)
- 안전성 속 유능함(OR-Bench Safe): 95.7% (답변 거부 없이 안전하게 수행)

즉, 수학 난제는 못 풀어도, 시키는 일은 빠르고 안전하게 처리하는 실무형 모델입니다.

3. 아쉬움: 다양성을 품지 못한 평가
정부가 세금을 쓰는 사업인 만큼 정량적 성능 평가는 중요합니다. 하지만 성능 줄 세우기에 밀려, 생태계에 가장 기여할 수 있는 모델(MIT 라이선스 + 데이터 공개)이 탈락했다는 점은 못내 아쉽습니다.

SKT가 성능과 개방을 다 잡은 모범 답안이라면, NC는 효율과 투명성이라는 또 다른 가치를 증명했습니다. 평가 기준에 오픈소스 생태계 기여도가 조금 더 비중 있게 다뤄졌다면 어땠을까요?

💡 결론

통과 기업분들의 국가대표 선발을 진심으로 축하합니다. 여러분 덕분에 한국어 LLM 생태계가 풍요러워졌습니다.

그리고 NC AI 팀에게도 리스펙을 보냅니다. 비록 국대 마크는 못 달았지만, 여러분이 공개한 데이터와 MIT 라이선스 모델은 전 세계 개발자들에게 가장 큰 선물이 되었습니다. 지원 사업과 무관하게, NC는 자본과 인프라가 충분하니 앞으로도 그 낭만을 지켜주시길 응원합니다.



likelovesupport
121




