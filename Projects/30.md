---
id: 30
category: Projects
title: 저번 글에서 현실에 아쉬움을 표했지만, 할 수 있는 것들은 있습니다. 이미 완성된 모델들과 도구들을 잘 조합한다면, 한 달에 수 십 만원을 내고 100B ~ 수 조 단위의 규모의 모델에서 하는 일을 16GB RAM CPU만 있는 노트북에서도 어느 정도 할 수 있습니다. 이제 Tiny MoA에게 눈과 손이 생겼습니다. Tool Calling 구현:
---
저번 글에서 현실에 아쉬움을 표했지만, 할 수 있는 것들은 있습니다. 이미 완성된 모델들과 도구들을 잘 조합한다면, 한 달에 수 십 만원을 내고 100B ~ 수 조 단위의 규모의 모델에서 하는 일을 16GB RAM CPU만 있는 노트북에서도 어느 정도 할 수 있습니다. 이제 Tiny MoA에게 눈과 손이 생겼습니다. Tool Calling 구현:

물론 이번에도 돈은 한 푼도 쓰지 않고, 로컬 CPU 환경에서만 돌렸습니다.

이제 Liquid AI LFM2.5 1.2B 모델(Brain)이 스스로 판단하여 도구를 사용합니다.


2. 터미널 제어 (Command Execution)

3. URL 딥 다이브 (URL Reading)

4. 언어의 장벽 제거 (Multilingual Support)
구글 번역 파이프라인을 내장하여, 사용자가 한국어로 질문하면 찰떡같이 영어로 번역해 Specialist에게 전달하고, 답변은 다시 자연스러운 한국어로 보여줍니다.

🛠️ 기술적 챌린지 (Behind the Scenes)
1.2B라는 작은 체급의 모델은 종종 "명령어를 실행해"라고 하면 진짜 명령어를 실행하는 게 아니라 "명령어를 실행하겠습니다..."라는 말을 생성해버리는 환각(Hallucination)이 있었습니다.

이를 해결하기 위해:
- Orchestrator에 '자연어 차단 필터'를 달아 엉뚱한 생성을 막고,
- Brain의 라우팅 프롬프트를 깎아서 "설명하지 말고 행동해(Do, don't explain)"를 주입했습니다.

📉 현황

많은 피드백이 필요한 단계입니다. 코드는 깃허브에 모두 공개되어 있습니다.

다음에는 파일 참조 기능 (@ 멘션 → Docling 변환), 한국 문화 및 역사 특화 RAG 연동, TUI 인터페이스 Cowork 구현 등을 할 것입니다.

🔗 GitHub: https://lnkd.in/gmY8afKq



33




