---
id: 56
category: Trends
title: Solar Open 표절 논란 종결
---
# Solar Open의 GLM 표절 논란 종결

새해 첫날부터 말도 많고 탈도 많았던 Solar Open의 GLM 표절 논란, 결국 From Scratch로 종결됐습니다. Upstage의 테크니컬 리포트를 보니 베낀 것이 아니라, 데이터 부족을 해결하기 위해 치열하게 고민한 흔적이 역력했습니다.

최근 LG AI Research의 K-EXAONE이 압도적인 체급과 품질로 한국형 LLM의 기준을 보여줬다면, 업스테이지의 Solar Open은 스타트업이 거대 자본과의 싸움에서 어떻게 생존하고 이길 수 있는지를 보여주는 효율과 기술의 총집합입니다.

Solar Open 테크니컬 리포트에서 발견한 3가지 핵심 포인트를 정리했습니다.

## 1. Architecture: 다이어트에 성공한 헤비급 (102B → 12B)

이 모델의 파라미터는 총 102B입니다. 하지만 실제로 추론할 때 머리를 굴리는 활성 파라미터는 12B에 불과합니다.

*   ✅ **No Dense Layers:** 보통 안정성을 위해 섞어 쓰는 Dense Layer를 과감히 없앴습니다. 오로지 MoE로만 채워서 구조를 단순화하고 속도를 높였습니다.
*   ✅ **초거대 어휘 사전:** 토크나이저 크기가 무려 19만 개입니다. 한국어와 영어를 더 적은 토큰으로 압축해서 처리하기 위함인데, 이는 추론 속도와 직결됩니다. (숫자도 쪼개서 봅니다)

## 2. The Secret Sauce: 없으면 만들고, 비효율은 쳐낸다

데이터가 부족하고 인프라가 비싼 스타트업의 한계를 기술로 돌파했습니다.

### 🧪 합성 데이터의 연금술 (Aggressive Synthetic Data)
한국어 데이터가 전 세계 웹의 0.8%밖에 안 된다고 합니다. 그래서 이들은 4.5조(4.5T) 토큰을 인공적으로 만들어서 채웠습니다. 단순히 양만 늘린 게 아니라, 다른 똑똑한 모델들의 사고 과정을 합성해 넣어 논리력을 키웠습니다. (전체 학습 데이터의 20% 이상)

*   **Low-to-High Curriculum:** 처음엔 이것저것 다 가르치다가, 나중엔 상위 35%의 고품질 데이터만 골라서 가르칩니다. 마치 초등 교육에서 고등 교육으로 넘어가는 것과 같습니다.
*   **Cycle:** 학습 후반부에는 합성 데이터 비중을 64%까지 늘립니다.

### 🔄 SnapPO (강화학습의 혁신)
이 모델의 필살기입니다. 기존 강화학습(RL)은 데이터 생성과 학습이 묶여 있어 무거웠습니다. 업스테이지는 데이터 생성과 학습하기를 분리했습니다.

*   **핵심:** 과거 모델이 만든 데이터를 쓰면 학습이 꼬일 수 있는데, 이를 수학적 보정(Importance Sampling)과 순환 구조(Cycle)로 해결했습니다.
*   **결과:** 인프라 수정 없이 GPU만 늘리면 성능이 정직하게 쭉쭉 올라갑니다(Linear Scalability).

### 🔍 난이도 감별사 (Difficulty-Aware Curation)
쉬운 문제만 풀면 바보가 되고, 너무 어려운 문제만 풀면 포기하죠? 여러 모델이 헷갈려하는 정도를 기준으로 문제의 난이도를 판별하는 측정기를 개발해, 모델 수준에 딱 맞는 데이터만 학습했습니다.

## 3. Reality Check: 글로벌 SOTA들과 계급장 떼고 붙어보면?

자, 이제 냉정한 현실입니다. Gemini 3.0 Pro, GLM-4.7, 그리고 LG K-EXAONE과 비교했을 때 Solar Open의 위치는 어디일까요?

**(1) 일반 지식 & 추론 (MMLU-Pro)**
*   🥇 **천상계 (God Tier):** Gemini 3.0 Pro (90.1점)
*   🥈 **최상위권:** GPT-5.1 (87.0점), GLM-4.7 (84.3점)
*   🥉 **추격자:** K-EXAONE (83.8점)
*   🏃 **Solar Open (80.4점):** 체급 차이(Active 12B)를 고려하면 선방했지만, 최상위권과는 격차가 있습니다. 하지만 K-EXAONE과는 3.4점 차이로, 가성비를 생각하면 훌륭합니다.

**(2) 수학 능력 (AIME 2025)**
*   🥇 **천상계:** GLM-4.7 (95.7점), Gemini 3.0 Pro (95.0점)
*   🥈 **최상위권:** K-EXAONE (92.8점) - LG 모델이 수학에서 정말 강력합니다.
*   🏃 **Solar Open (84.3점):** 수학에서는 체급의 한계가 명확히 드러납니다. 복잡한 수리 추론이 필요하다면 상위 모델을 써야 합니다.

**(3) 코딩 능력 (LiveCodeBench v6)**
*   🥇 **천상계:** Gemini 3.0 Pro (90.7점)
*   🥈 **최상위권:** GPT-5.1 (87.0점), GLM-4.7 (84.9점)
*   🥉 **추격자:** K-EXAONE (80.7점)
*   🏃 **Solar Open (74.2점):** 코딩 전용으로 쓰기엔 조금 아쉽습니다.

**(4) Solar의 반격: 전문 분야 (Medical/Law)**
하지만 '한국어 전문직' 영역으로 오면 이야기가 달라집니다.
*   **의료(KorMedMCQA):** Solar Open (84.4점) vs gpt-oss-120b (75.8점)
*   의료, 법률, 금융 등 특정 도메인에서는 체급이 더 큰 모델들을 압도합니다.

---

## 💡 마치며: 누구를 위한 모델인가?

K-EXAONE이 압도적인 퍼포먼스로 한국형 GPT-4의 가능성을 보여줬다면, Solar Open은 더 효율적이고 현실적으로 쓰기 좋은 모델입니다.

*   🛑 **K-EXAONE:** 성능은 최강이지만, 라이선스 제약(상업적 재배포 제한, 역공학 금지)이 있어 마음대로 뜯어고쳐 쓰기엔 부담스럽습니다.
*   ✅ **Solar Open:** 성능은 SOTA보다 한 수 아래지만, 라이선스가 자유롭고(Open Weights) 운영 비용이 저렴합니다. (K-EXAONE의 절반 수준)

**결론:**
1.  "성능이 전부다" 👉 GLM-4.7이나 K-EXAONE을 쓰세요.
2.  "가성비 좋은 모델을 만들고 싶다" 👉 Solar Open이 정답입니다.

업스테이지는 이 논문을 통해 데이터가 부족한 언어도 합성 데이터와 기술(SnapPO)로 극복할 수 있다는 방법론을 전 세계에 증명했습니다. 한국 AI 생태계가 단순히 따라가는 것을 넘어 방법을 제시하는 단계로 가고 있다는 점이 고무적입니다.
