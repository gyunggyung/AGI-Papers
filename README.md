# ğŸš€ AGI-Papers

![AGI-Papers](https://img.shields.io/badge/AGI--Papers-2026-blue?style=for-the-badge&logo=github)
![Topic](https://img.shields.io/badge/Topic-AGI%20%7C%20Agents%20%7C%20Trends-green?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Active-important?style=for-the-badge)

> **Toward Artificial General Intelligence (AGI) in 2026.**  
> Exploring the frontiers of AI, LLMs, and Autonomous Agents.

## ğŸ“Œ Introduction

2026ë…„, AGIì— ê·¸ ì–´ëŠ ë•Œë³´ë‹¤ ê°€ê¹Œìš´ ì‹œëŒ€ê°€ ë„ë˜í–ˆìŠµë‹ˆë‹¤.  
ì´ ì €ì¥ì†ŒëŠ” **AGI(Artificial General Intelligence)** ë¡œ í–¥í•˜ëŠ” ì—¬ì •ì—ì„œ ì¤‘ìš”í•œ ë…¼ë¬¸ë“¤ì„ ë¦¬ë·°í•˜ê³  ì•„ì¹´ì´ë¹™í•˜ëŠ” ê³µê°„ì…ë‹ˆë‹¤.

ì£¼ë¡œ ì œ **[LinkedIn](https://www.linkedin.com/in/kiwoong-yeom/)** ì—ì„œ ë‹¤ë£¬ ë…¼ë¬¸ë“¤ì— ëŒ€í•œ ì‹¬ë„ ìˆëŠ” ë¦¬ë·°ê°€ ì—…ë¡œë“œë˜ë©°, ë•Œë¡œëŠ” ì†Œì…œ ë¯¸ë””ì–´ì— ê³µìœ í•˜ê¸° ì „ì˜ **Pre-release ì¸ì‚¬ì´íŠ¸**ë‚˜ ë‚ ê²ƒì˜ ìƒê°ë“¤ì´ ì´ê³³ì— ë¨¼ì € ê¸°ë¡ë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ“‚ Archives

ê³¼ê±°ì— ì •ë¦¬í–ˆë˜ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ëŠ” ì•„ë˜ ë§í¬ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ğŸ‘‰ **[Past AGI-Papers (Pre-2026)](https://github.com/gyunggyung/AGI-Papers/blob/master/Pre-README.md)**

---

## ğŸ“š Contents

- [ğŸ”¥ Trends & Industry](#trends--industry)
- [ğŸ¤– Agents](#agents)
- [ğŸ§  Architecture](#architecture)
- [ğŸ“š Pre-Training](#pre-training)
- [ğŸ¯ Post-Training](#post-training)
- [ğŸ—‚ï¸ RAG & Knowledge](#rag--knowledge)
- [ğŸ’» On-Device AI](#on-device-ai)
- [ğŸš€ Projects](#projects)

---

## <a id="trends--industry"></a>ğŸ”¥ Trends & Industry

*   [**Hugging Face CEOì˜ í•œêµ­ AI ëª¨ë¸ ì‘ì›**](./Trends/53.md)  
    *SKT A.X, LG AI, Upstage ë“± í•œêµ­ ëª¨ë¸ì˜ ì „ì„±ì‹œëŒ€.*
*   [**CES 2026: AMD Lisa Suì™€ Liquid AI**](./Trends/48.md)  
    *AMDê°€ ì„ íƒí•œ íŒŒíŠ¸ë„ˆ.*
*   [**êµ­ê°€ëŒ€í‘œ AI í”„ë¡œì íŠ¸ 1ì°¨ ê²°ê³¼**](./Trends/43.md)  
    *LG, SKT, Upstage ì„ ë°œê³¼ íƒˆë½ ê¸°ì—…ë“¤ì˜ í–‰ë³´.*
*   [**Post-trainingì˜ í•œê³„**](./Trends/40.md)  
    *ì™œ ëª¨ë¸ì€ í•™ìŠµì´ ëë‚˜ë©´ ë” ì´ìƒ ë˜‘ë˜‘í•´ì§€ì§€ ì•ŠëŠ”ê°€?*
*   [**LLM ê°œë°œê³¼ ì‚¬ë‚´ ì •ì¹˜**](./Trends/39.md)  
    *ì‹¤ë¬´ì vs ê²½ì˜ì§„ì˜ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê´€ì  ì°¨ì´.*

## <a id="agents"></a>ğŸ¤– Agents

*   [**OctoTools**](./Agents/99.md)  
    *Training-free LLM Agent Framework.*
*   [**Chain-of-Draft(CoD)**](./Agents/93.md)  
    *CoTì˜ ì¥ì ì„ ìœ ì§€í•˜ë©´ì„œ í† í° ì‚¬ìš©ëŸ‰ê³¼ ê³„ì‚° ë¹„ìš©ì„ ì¤„ì´ëŠ” íšê¸°ì ì¸ ì ‘ê·¼ë²•.*
*   [**Adaptation of Agentic AI**](./Agents/80.md)  
    *ê±°ëŒ€ ëª¨ë¸ íŠœë‹ë³´ë‹¤ ë„êµ¬ íŠœë‹ì´ íš¨ìœ¨ì ì¸ ì´ìœ  (T2 > A2).*
*   [**Memory in the Age of AI Agents**](./Agents/77.md)  
    *ì—ì´ì „íŠ¸ ê¸°ì–µì˜ í˜•íƒœ, ê¸°ëŠ¥, ì—­ë™ì„±ì— ëŒ€í•œ ê³ ì°°.*
*   [**LFM-Scholar: Local Research Agent**](./Agents/27.md)  
    *LFM-Scholar, an AI agent that automatically organizes related research.*
*   [**Detailed balance in LLM-driven agents**](./Agents/23.md)
*   [**World Models Research**](./Agents/11.md)  
    *World Knowledge Injection vs Specific Tasks.*
*   [**Mixture-of-Models**](./Agents/9.md)  
    *Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation.*
*   [**AIRS-Bench**](./Agents/5.md)  
    *Frontier AI Research Science Agentsë¥¼ ìœ„í•œ íƒœìŠ¤í¬.*

## <a id="architecture"></a>ğŸ§  Architecture

*   [**LLMì˜ "ì…ë ¥ ê¸¸ì´ ì œê³±(N^2)"ì˜ ì €ì£¼**](./Architecture/90.md)  
    *ëˆ„ê°€ ë¨¼ì € ëŠì–´ë‚¼ ê²ƒì¸ê°€?*
*   [**Mistral Large 3: íš¨ìœ¨ì„±ì˜ ê·¹ëŒ€í™”**](./Architecture/88.md)
*   [**í‘œì¤€ì´ ëœ V3 ì•„í‚¤í…ì²˜**](./Architecture/86.md)  
    *Mistral Large 3, Kimi K2 ê·¸ë¦¬ê³  DeepSeek V3.2 ë¶„ì„.*
*   [**Ai2 Olmo 3**](./Architecture/85.md)  
    *ì„±ëŠ¥ë³´ë‹¤ëŠ” ê³¼ì •ì˜ íˆ¬ëª…ì„±ì— ì§‘ì¤‘í•œ LLM ì—°êµ¬ì˜ êµê³¼ì„œ.*
*   [**Liquid AI LFM2-2.6B-Exp íŠœë‹ê¸°**](./Architecture/58.md)  
    *ë…¼ë¬¸ Related Work ì„¹ì…˜ì„ í†µì§¸ë¡œ ìƒì„±í•˜ëŠ” ë„êµ¬ ì œì‘.*
*   [**Nemotron-3-Nano-30B-A3B**](./Architecture/50.md)  
    *Qwen3ë³´ë‹¤ ë¹ ë¥´ê³  ê°•ë ¥í•œ Mamba-2 í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸.*
*   [**DeepSeek Engram**](./Architecture/44.md)  
    *ê¸°ì–µì„ íš¨ìœ¨í™”í•˜ì—¬ ì—°ì‚° ë‚­ë¹„ë¥¼ ì¤„ì´ëŠ” ìƒˆë¡œìš´ í¬ì†Œì„± ì¶•.*
*   [**2026ë…„ì˜ í†µë… íŒŒê´´: 90M, 600M ëª¨ë¸**](./Architecture/41.md)  
    *ì´ˆì†Œí˜• ëª¨ë¸ë“¤ì˜ ë†€ë¼ìš´ ì§€ì‹œ ì´í–‰ ëŠ¥ë ¥.*
*   [**Sakana AI RePo**](./Architecture/38.md)  
    *ìœ„ì¹˜ ì •ë³´ë¥¼ ì¬ì„¤ê³„(Re-position)í•˜ë¼.*
*   [**DeepSeek vs Qwen (A3B MoE)**](./Architecture/35.md)  
    *ì •ë°˜ëŒ€ì˜ ì„¤ê³„ ì² í•™ ë¶„ì„.*
*   [**Pau Labarta Bajo's Insight**](./Architecture/27.md)  
    *ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸.*
*   [**Generative Modeling via Drifting**](./Architecture/6.md)

## <a id="pre-training"></a>ğŸ“š Pre-Training

*   [**LLM í•™ìŠµ íš¨ìœ¨í™” ë°©ì•ˆ: ì¸ê°„ì˜ ì–¸ì–´ ìŠµë“ ë°©ì‹**](./Pre_Training/97.md)
*   [**Diffusion LLM (100B Parameters)**](./Pre_Training/83.md)  
    *30B ëª¨ë¸ë³´ë‹¤ 2ë°° ë¹ ë¥¸ ë³‘ë ¬ ìƒì„± ëª¨ë¸ì˜ ë“±ì¥.*
*   [**RoPEê°€ ì •ë³´ë¥¼ ìœ ì‹¤í•˜ê³  ìˆë‹¤?**](./Pre_Training/79.md)  
    *í‘¸ë‹¨ëŒ€ ì—°êµ¬ì§„ì˜ ì¶©ê²©ì ì¸ ë°œê²¬ê³¼ í•´ê²°ì±….*
*   [**Python ì¬ê·€ë¡œ ì‹œì‘í•˜ëŠ” 1,000ë§Œ í† í° ì‹œëŒ€**](./Pre_Training/60.md)
*   [**Solar Openì˜ GLM í‘œì ˆ ë…¼ë€ ì¢…ê²°**](./Pre_Training/56.md)  
    *From Scratch ê°œë°œì˜ ì¹˜ì—´í•œ í”ì .*
*   [**Sakana AI: ìœ„ì¹˜ ì •ë³´(Positional Embeddings)ëŠ” ë²„ë ¤ë¼**](./Pre_Training/47.md)
*   [**CALM: Continuous Autoregressive Language Models**](./Pre_Training/34.md)
*   [**Beyond Transformers 2**](./Pre_Training/13.md)  
    *ë©ì¹˜ ê²½ìŸì„ ë„˜ì–´ ìƒê°ê³¼ ë³¸ì§ˆë¡œ.*
*   [**What LLMs Think When You Don't Tell Them?**](./Pre_Training/4.md)

## <a id="post-training"></a>ğŸ¯ Post-Training

*   [**Gemma 3 ëª¨ë¸ì˜ í•µì‹¬ ëª©í‘œ ë° íŠ¹ì§•**](./Post_Training/98.md)
*   [**Emergent Misalignment**](./Post_Training/96.md)  
    *ì·¨ì•½í•œ ì½”ë“œë¥¼ ë°°ìš´ AIì˜ ìœ„í—˜í•œ ì¼íƒˆ.*
*   [**Stabilizing RL with LLMs**](./Post_Training/92.md)  
    *í™”ë ¤í•œ ê¸°êµë³´ë‹¤ ìˆ˜í•™ì  ê¸°ë³¸ê¸°ê°€ ì¤‘ìš”í•œ ì´ìœ .*
*   [**LFM2 1.2B ê¸°ë°˜ í•œêµ­ì–´-ì˜ì–´ ë²ˆì—­ê¸°**](./Post_Training/89.md)
*   [**LFM2 1.2B í•œêµ­ì–´ ì˜ì–´ ë²ˆì—­ê¸° ì œì‘**](./Post_Training/87.md)  
    *Liquid AI 1.2B vs Google 4B.*
*   [**Pau Labarta Bajo's Insight (Post-Training)**](./Post_Training/87.md)
*   [**ìµœì‹  AI íŠ¸ë Œë“œ í•µì‹¬ ë°œê²¬ ìš”ì•½**](./Post_Training/82.md)
*   [**Small Language Model for Translation**](./Post_Training/81.md)  
    *Advice for AI engineers.*
*   [**Yann LeCun: World Modelì˜ ì¤‘ìš”ì„±**](./Post_Training/78.md)  
    *LLMì€ ë¬¼ë¦¬ ì„¸ê³„ë¥¼ ë°°ìš¸ ìˆ˜ ì—†ë‹¤?*
*   [**Liquid AI LFM2-1.2B íŠœë‹ ì‹¤íŒ¨ê¸°**](./Post_Training/76.md)  
    *í•œêµ­ì–´-ì˜ì–´ ë²ˆì—­ RL(GRPO) í•™ìŠµ ì‹¤íŒ¨ì™€ êµí›ˆ.*
*   [**Sebastian Raschka, PhD: "Ahead of AI"**](./Post_Training/59.md)  
    *ê¸°ë³¸ê¸°ë¶€í„° ìµœì‹  íŠ¸ë Œë“œê¹Œì§€.*
*   [**í•œêµ­ì–´ LLM í•™ìŠµ ë°ì´í„°ì˜ ë¶€ì¬**](./Post_Training/51.md)  
    *Pre-trainingë¶€í„° GRPOê¹Œì§€ì˜ í—˜ë‚œí•œ ì—¬ì •.*
*   [**Anthropicì˜ ìƒíƒœê³„ ì¡°ì´ê¸°**](./Post_Training/49.md)  
    *OpenCode ì°¨ë‹¨ê³¼ Claude Code ì‚¬ìš©ëŸ‰ ì œí•œì˜ ì•„ì‰¬ì›€.*
*   [**GDPO: Multi-reward RL**](./Post_Training/46.md)  
    *GRPOì˜ ì•½ì ì„ ê·¹ë³µí•œ ìƒˆë¡œìš´ ê°•í™”í•™ìŠµ ê¸°ë²•.*
*   [**AI ê±°í’ˆë¡ ì˜ ë³¸ì§ˆ**](./Post_Training/2.md)  
    *ì‹œì¥ ì¶•ì†Œê°€ ì•„ë‹Œ ìˆ˜ê¸‰ ì•ˆì •í™”ì™€ ì‚°ì—…ì˜ ì„±ìˆ™.*
*   [**iGRPO**](./Post_Training/1.md)  
    *Self-Feedback-Driven LLM Reasoning.*

## <a id="rag--knowledge"></a>ğŸ—‚ï¸ RAG & Knowledge

*   [**HippoRAG 2**](./RAG/100.md)  
    *ì¸ê°„ì˜ ê¸°ì–µ ë©”ì»¤ë‹ˆì¦˜ì„ ëª¨ë°©í•œ ë¹„ëª¨ìˆ˜ì  ì—°ì† í•™ìŠµ (Bio-inspired Continual Learning).*
*   [**DeepSeek-V3 vs V3.2: ì•„í‚¤í…ì²˜ì˜ ì§„í™”**](./RAG/94.md)  
    *ì•„í‚¤í…ì²˜ì˜ ì§„í™”ì™€ ê¸°ìˆ ì  ëª©í‘œì .*
*   [**From Code Foundation Models to Agents**](./RAG/84.md)
*   [**ADR-Bench ì „ë¬¸ê°€ í‰ê°€**](./RAG/55.md)  
    *DeepSeek-v3.2ë¥¼ ì••ë„í•œ íš¨ìœ¨ì ì¸ ì—ì´ì „íŠ¸ ëª¨ë¸.*
*   [**vLLMì˜ ìŠ¹ë¦¬: ì••ë„ì ì¸ ì†ë„**](./RAG/29.md)  
    *í‘œì¤€ì´ ë˜ê¸°ê¹Œì§€.*
*   [**RAG & Agent Memory 4ì„ **](./RAG/10.md)  
    *GraphSearch, S-RAG, xMemory ë“± ìµœì‹  ë…¼ë¬¸ ì†Œê°œ.*

## <a id="on-device-ai"></a>ğŸ’» On-Device AI

*   [**Liquid AI 1.2B vs Google 4B**](./On_Device/45.md)  
    *Pau Labarta Bajo's Local AI Insight.*
*   [**êµ­ê°€ëŒ€í‘œ AI íƒˆë½ ê·¸ í›„ (On-Device Focus)**](./On_Device/42.md)  
    *í˜„ì‹¤ì ì¸ ì§„ë‹¨ê³¼ ì¤‘êµ­ ëª¨ë¸ê³¼ì˜ ë¹„êµ.*
*   [**ë¡œì»¬ LLM êµ¬ë™ì˜ 6ê°€ì§€ í˜„ì‹¤ì  ë°©ë²•**](./On_Device/33.md)
*   [**LLM ì§€ëŠ¥ì˜ ë¯¼ë‚¯ê³¼ í•œê³„**](./On_Device/3.md)  
    *ë²¤ì¹˜ë§ˆí¬ëŠ” ìˆ˜ì„ì´ì§€ë§Œ í˜„ì¥ì—ì„œëŠ” ë¶€ì¡±í•œ ì´ìœ .*

## <a id="projects"></a>ğŸš€ Projects

*   [**Docling-Translate**](./Projects/91.md)  
    *CLIì˜ ë²ˆê±°ë¡œì›€ì„ í•´ê²°í•œ Streamlit ê¸°ë°˜ ë²ˆì—­ ë„êµ¬.*
*   [**LFM-Scholar**](./Projects/57.md)  
    *ë…¼ë¬¸ Related Work ìë™ ì‘ì„±ì„ ìœ„í•œ LLM ë„êµ¬.*
*   [**HybriKo: í•˜ì´ë¸Œë¦¬ë“œ RNN+Attention**](./Projects/54.md)  
    *Google Griffinê³¼ Liquid AI LFM2ì—ì„œ ì˜ê°ì„ ë°›ì€ ì•„í‚¤í…ì²˜.*
*   [**Claude Vibe Coding**](./Projects/52.md)  
    *ë³µì¡í•œ ë°±ì—”ë“œëŠ” AIì—ê²Œ ë§¡ê¸°ê³  ê³µì›ì—ì„œ ëŸ¬ë‹í•˜ê¸°.*
*   [**HybriKo-117M**](./Projects/37.md)  
    *A100 8ì¥ìœ¼ë¡œ ë§Œë“  ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´ Function Calling ëª¨ë¸.*
*   [**HybriKo-117M-LinuxFC**](./Projects/36.md)  
    *í•œêµ­ì–´ë¥¼ ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´ë¡œ ë°”ê¿”ì£¼ëŠ” ì´ˆê²½ëŸ‰ ëª¨ë¸ ê°œë°œê¸°.*
*   [**Tiny MoA**](./Projects/32.md)  
    *ì‹œê°„ë‹¹ $100 íƒœìš°ëŠ” AI vs CPUë¡œ ëŒë¦¬ëŠ” ê°€ì„±ë¹„ ë©€í‹° ì—ì´ì „íŠ¸.*
*   [**52-Layer HybriKo-430M**](./Projects/31.md)  
    *T4 GPU í•˜ë‚˜ì— ìµœì‹  ì•„í‚¤í…ì²˜ë¥¼ ìš°ê²¨ë„£ì€ ì‹¤í—˜ì‘.*
*   [**Tiny MoA Tool Calling**](./Projects/30.md)  
    *16GB ë…¸íŠ¸ë¶ì—ì„œ êµ¬í˜„í•œ ë¡œì»¬ ì—ì´ì „íŠ¸ì˜ ëˆˆê³¼ ì†.*
*   [**vLLM & SGLang in llama.cpp**](./Projects/28.md)  
    *CPU ì¶”ë¡  ì†ë„ 1.8ë°° í–¥ìƒ.*
*   [**SEAL: ìŠ¤ìŠ¤ë¡œ Fine-tuningí•˜ëŠ” ì—ì´ì „íŠ¸**](./Projects/26.md)  
    *ê°€ëŠ¥ì„±ê³¼ í•œê³„.*
*   [**Clawdbot vs ë¡œì»¬ AI**](./Projects/25.md)  
    *API ì—†ëŠ” ì§„ì •í•œ ì˜¨ë””ë°”ì´ìŠ¤ AIë¥¼ í–¥í•˜ì—¬.*
*   [**Tiny MoA: ì§„ì •í•œ ì˜¨ë””ë°”ì´ìŠ¤ AI**](./Projects/24.md)  
    *Clawdbot is cool, but Tiny MoA runs on CPU.*
*   [**ë¬´í•œ ë£¨í”„ ë°”ì´ë¸Œ ì½”ë”©**](./Projects/22.md)  
    *"í…ŒìŠ¤íŠ¸ ì„±ê³µí•  ë•Œê¹Œì§€ ê³„ì†í•´" í•œë§ˆë””ë¡œ ê°œë°œ ëë‚´ê¸°.*
*   [**Insight Agents**](./Projects/21.md)  
    *An LLM-Based Multi-Agent System for Data Insights.*
*   [**Gemini-Claw ê°œë°œê¸°**](./Projects/20.md)  
    *2ì‹œê°„ ë§Œì— ë§Œë“ , ìŠ¤ìŠ¤ë¡œ ì½”ë“œë¥¼ ì§œê³  ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì—ì´ì „íŠ¸.*
*   [**Gemini-Claw íŒŒì¼ ì¡°ì‘ ê¸°ëŠ¥**](./Projects/19.md)  
    *"í„°ë¯¸ë„ ì¡°ì‘ ê¸°ëŠ¥ì´ë‚˜ ë„£ì–´ë³¼ê¹Œ?"*
*   [**Gemini 3 Pro + ë‚¯ì„  API**](./Projects/18.md)  
    *ê¸°ëŒ€ ì´ìƒì˜ ì½”ë“œ í€„ë¦¬í‹°ì™€ ì¬ë¯¸.*
*   [**AIì— ëŒ€í•œ ë‘ë ¤ì›€ vs í¥ë¯¸**](./Projects/17.md)  
    *OpenClaw, í™˜ê° ì¸ìš©, Vibe Coding í˜„ìƒì— ëŒ€í•œ ë‹¨ìƒ.*
*   [**ìŠ¤ìŠ¤ë¡œ ì›¹í˜ì´ì§€ë¥¼ ë§Œë“¤ê³  ê²€ì¦í•˜ëŠ” AI**](./Projects/16.md)
*   [**Gemini-Claw ì˜¤í”¼ìŠ¤ ìƒì„±**](./Projects/15.md)  
    *ë¡œì»¬ í´ë”ë¥¼ ë¶„ì„í•´ 94ì´ˆ ë§Œì— í’€ íŒ¨í‚¤ì§€ ìƒì„±.*
*   [**GPT êµ¬ì¡°ì˜ í•œê³„ë¥¼ ë„˜ì–´**](./Projects/14.md)  
    *Liquid AI, TII, NVIDIAì˜ ìƒˆë¡œìš´ ì‹œë„ë“¤.*
*   [**Gemini-Claw ì„±ëŠ¥ vs ë³´ì•ˆ**](./Projects/12.md)  
    *LLM ì—ì´ì „íŠ¸ì˜ ìœ„í—˜í•œ ì ì¬ë ¥.*
*   [**1.2B ëª¨ë¸ë¡œ PPT ë§Œë“¤ê¸°**](./Projects/8.md)  
    *ì†Œí˜• ëª¨ë¸ì˜ ê°€ëŠ¥ì„±.*
*   [**ìµœê·¼ êµ¬í˜„í•œ AI í”„ë¡œì íŠ¸ ë° ì„±ê³¼**](./Projects/7.md)

---

## ğŸ“¬ Connect

*   [<img src="https://img.shields.io/badge/LinkedIn-Dougy-blue?style=flat&logo=linkedin&logoColor=white" />](https://www.linkedin.com/in/kiwoong-yeom) **Kiwoong Yeom**
*   [<img src="https://img.shields.io/badge/GitHub-gyunggyung-black?style=flat&logo=github&logoColor=white" />](https://github.com/gyunggyung)
*   ğŸ“§ **Contact:** newhiwoong@gmail.com

---
*Disclaimer: The views and opinions expressed in these reviews are those of the author and do not necessarily reflect the official policy or position of any other agency, organization, employer or company.*
