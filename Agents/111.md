---
id: 111
category: Agents
title: HUMANLM: State Alignment for User Simulation
---
# HUMANLM: 진정한 페르소나는 '마음'에서 나온다

> **사용자의 말투만 흉내 내는 앵무새는 가라. 신념, 가치, 감정까지 시뮬레이션하는 'State Alignment'의 등장.**

## 1. 논문 개요

*   **제목**: HUMANLM: State Alignment for User Simulation
*   **문제 의식**: 기존의 사용자 시뮬레이터(User Simulator)들은 사용자의 과거 발화 데이터를 학습해 **'말투(Response Imitation)'**만 따라 했습니다. 하지만 진짜 사람은 같은 상황에서도 자신의 신념, 기분, 목표에 따라 다르게 행동합니다.
*   **제안**: 사용자의 **심리적 상태(State)**를 명시적으로 모델링하고, 이를 LLM과 정렬(Alignment)시키는 프레임워크인 **HUMANLM**을 제안합니다.

---

## 2. 핵심 기술: State Alignment

HUMANLM은 인간의 내면을 6가지 잠재 상태(Latent State)로 정의합니다.

### 6가지 마음의 차원 (Attribute Dimensions)
1.  **신념 (Belief)**: 사실에 대한 믿음이나 세계관.
2.  **목표 (Goal)**: 대화나 행동을 통해 이루고자 하는 의도.
3.  **가치 (Value)**: 도덕적 판단 기준이나 선호.
4.  **입장 (Stance)**: 특정 주제에 대한 태도 (찬성/반대).
5.  **감정 (Emotion)**: 현재의 기분 상태.
6.  **소통 방식 (Communication Style)**: 직설적, 우회적, 방어적 등 대화 스타일.

### 학습 방법
단순히 "이 사람처럼 말해"라고 시키는 것이 아니라, **"이 사람의 신념과 감정이 이렇다면, 어떻게 말하겠는가?"**를 학습시킵니다.
*   **State Alignment**: 강화학습(RL)을 통해 모델이 겉으로 드러난 발화뿐만 아니라, 그 이면에 있는 위 6가지 상태를 정확히 추론하도록 훈련합니다.
*   **보상 설계**: 모델이 추론한 상태가 실제 사용자의 프로파일과 일치할수록 높은 보상을 줍니다.

---

## 3. 실험 결과 (HUMANUAL Benchmark)

연구진은 23,000명의 사용자 데이터를 바탕으로 구축한 **HUMANUAL** 벤치마크에서 성능을 검증했습니다.
*   **성능**: 기존 SFT 모델 대비 **16.3% 성능 향상**.
*   **Turing Test**: 실제 사람을 대상으로 한 블라인드 테스트에서, 76.6%의 참가자가 HUMANLM의 반응을 "진짜 사람 같다"고 평가했습니다. 이는 단순 모방 모델보다 월등히 높은 수치입니다.

---

## 4. 결론 및 활용 방안

HUMANLM은 **"시뮬레이션의 깊이"**를 한 단계 끌어올렸습니다.
*   **소셜 미디어 시뮬레이션**: 특정 정책이나 뉴스에 대해 대중이 어떻게 반응할지 더 정확하게 예측할 수 있습니다.
*   **NPC & 게임**: 플레이어와 감정적으로 교류하는 깊이 있는 NPC를 만들 수 있습니다.
*   **개인화 비서**: 나의 단순한 명령뿐만 아니라, 나의 숨겨진 의도와 가치관까지 파악하여 행동하는 비서를 구현할 수 있습니다.

이제 에이전트는 단순히 일을 대신 해주는 기계가 아니라, **나를 이해하는(Undertstand) 존재**로 진화하고 있습니다.
