---
id: 59
category: Post_Training
title: 1. Sebastian Raschka, PhD의 "Ahead of AI" (기본기 & 최신 트렌드)
---
1. Sebastian Raschka, PhD의 "Ahead of AI" (기본기 & 최신 트렌드)
단순한 AI 뉴스 레터가 아닙니다. <Build a Large Language Model (From Scratch)>의 저자답게, 최신 논문과 기술을 요즘 화제인 From Scratch 원리부터 꼼꼼하게 짚어줍니다.

최근에는 'DeepSeek-V3 아키텍처 분석'이나 '2025년 LLM 현황' 같은 글들이 매우 인상적이었습니다. 겉핥기식 정보가 아니라, 모델의 내부 작동 방식을 이해하고 싶다면 반드시 구독해야 할 매거진입니다.

🔗 Magazine: https://lnkd.in/g7Q-iupz


2. Nathan Lambert의 "Reinforcement Learning from Human Feedback" (Post-Training의 정석)
LLM의 성능을 결정짓는 핵심은 이제 Pre-training을 넘어 Post-training(사후 학습)으로 넘어가고 있습니다. 하지만 RLHF(인간 피드백 기반 강화학습)는 여전히 진입장벽이 높죠.

Ai2(Allen Institute for AI)에서 LLM Post-training Lead로 재직 중인 Nathan Lambert님이 집필하고 있는 이 책(웹사이트)은, RLHF의 정의부터 보상 모델링, RLVR, Inference-time Scaling, Tool Use, Character Training 같은 최신 기법들을 체계적으로 정리해 줍니다. 단순한 블로그 글들을 넘어, 교과서처럼 두고두고 볼 수 있는 깊이 있는 자료입니다.

🔗 Book: https://rlhfbook.com


3. Mihail Eric의 "CS146S: The Modern Software Developer" (AI-Native 개발)
"AI가 코딩을 다 해주면 개발자는 무엇을 해야 할까요?" 이 질문에 대한 답이 여기에 있습니다.

Stanford University CS146S 강의는 단순한 코딩이 아니라, AI Agent, MCP, 테스팅, 보안 등 AI 시대에 맞는 새로운 소프트웨어 엔지니어링의 패러다임을 제시합니다. Claude Code 창시자 Boris Cherney를 포함해서 여러 현업 전문가들이 참여한 강연 자료들도 포함되어 있습니다.

강의 비디오가 제공되지 않는 것 같아서 아쉽지만, 과제와 강의 슬라이드, 그리고 관련 자료들 만으로도 충분히 깊이 있는 학습이 가능합니다.

🔗 Course: https://lnkd.in/ggngATYP


4. Maxime Labonne의 "LLM Course" (실전 로드맵)
LLM 엔지니어를 꿈꾸는 사람들의 바이블과도 같은 곳입니다. 수학적 기초부터 LLM 파인튜닝, RAG, 양자화(Quantization)까지, 방대한 주제를 실습 가능한 Colab 노트북과 함께 제공합니다.


🔗 GitHub: https://lnkd.in/geRZ7YFt


5. 저를 팔로우하거나 1촌을 맺어주세요.
저는 영어로 글을 쓰지 않습니다. 이런 글들을 한글로 이해하기 쉽게 전달해 드립니다. 언어 장벽 없이 가장 빠른 AI 기술 소식을 제 피드에서 확인하세요.


마치며
물론 이 외에도 훌륭한 자료들은 세상에 많으니 더 찾아보시길 바랍니다.


마지막으로, 이 방대한 내용들을 지금 당장 전부 상세하게 정독해야 한다는 부담은 갖지 않으셨으면 합니다.


저는 Reinforcement Learning from Human Feedback 부터 봐보려고 합니다. 모두 즐거운 독서 되시길 바랍니다.

76

love
마음에 쏙듬



