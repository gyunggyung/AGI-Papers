---
id: 23
category: Architecture
title: Detailed balance in large language model-driven agents
---
Anthropic의 Claude가 코딩에서 압도적인 퍼포먼스를 보여주는 이유는 단순히 학습 데이터가 좋아서가 아니었습니다. 그 비밀이 물리학의 법칙으로 증명되었습니다. 이 논문은 LLM이 단순히 다음 단어를 예측하는 기계가 아니라, '최소 작용의 원리(Least Action Principle)'라는 거시적인 물리 법칙을 따른다는 사실을 밝혀냈습니다. 

이 논문을 통해 Claude가 왜 코딩 몬스터인지, 그리고 우리가 어떻게 이런 모델을 만들 수 있는지 4가지 핵심으로 정리했습니다.

📄 제목: Detailed balance in large language model-driven agents
👥 저자: Zhuo-Yang Song et al. (Peking University Physics)

1. Claude의 뇌 구조: 깊은 골짜기로 굴러떨어지는 공

연구진은 모델들에게 간단한 단어 생성 게임을 20,000번 시켰습니다. 결과가 흥미롭습니다.

 - GPT-5 Nano (탐험가형): 20,000번 시도 중 무려 645개의 서로 다른 정답을 찾아냈습니다. 호기심이 많고 여기저기 둘러봅니다.
 - Claude-4 (목적 지향형): 20,000번 시도 중 단 5개의 상태로만 수렴했습니다.

이것이 Claude가 코딩을 잘하는 이유입니다. 코딩은 창의성보다 정확성이 생명입니다. 오타 하나에도 컴파일이 불가능한 환경에서, Claude는 '잠재 함수(Potential Function)'라는 에너지 지형의 골짜기가 매우 깊고 가파르게 형성되어 있습니다.

다른 모델들이 이 코드도 괜찮고, 저 코드도 괜찮아 하며 언덕을 산책할 때, Claude는 공을 놓자마자 가장 확실한 정답(바닥)으로 직행합니다.

2. 물리학으로 증명된 '압도적 성능'의 실체: 상세 균형(Detailed Balance)

우리는 흔히 Claude가 정답 하나만 고집하면 과적합(Overfitting) 된 거 아니야?라고 의심합니다. 하지만 논문은 이것이 과적합이 아니라 '상세 균형'이라는 물리 법칙을 완벽히 따르는 상태임을 증명했습니다.

모델이 꼼수를 부리는 게 아닙니다. 에이전트가 상태를 이동할 때, 불필요한 움직임(Action)을 최소화하며 에너지 효율적으로 정답을 찾아가는 물리적 현상입니다. 사용자가 느꼈던 Claude는 말귀를 빨리 알아듣고 빠릿하다는 느낌은, 실제로 모델이 '물리적 작용(Action)'을 최소화하고 있었기 때문입니다.

3. 우리 모델을 Claude처럼 만드는 법: 골짜기를 더 깊게 파라

그렇다면 우리 모델도 Claude처럼 만들 수 있을까요? 논문은 아주 구체적인 엔지니어링 팁을 줍니다. 바로 '다수결 투표(Majority Voting)'의 물리학적 재해석입니다.

API를 호출할 때 M개의 후보를 뽑고, 그중 n번 이상 나온 답을 선택하는 단순한 로직이 아닙니다. 이 과정을 거치면 수학적으로 잠재 함수의 깊이가 n배 증폭(V' ≈ nV) 됩니다.

 - 효과: 골짜기가 n배 더 깊어집니다.
 - 결과: 에이전트의 '작용(Action)'이 1/n로 줄어듭니다.

즉, 어설픈 모델이라도 투표 수를 늘려서 선택하면, 강제로 Claude처럼 목적 지향적인 수렴형 모델로 변신시킬 수 있다는 뜻입니다.

4. 미래의 모델: 상황에 따라 변신하는 AI

하지만 무조건 Claude처럼 수렴하는 게 정답은 아닙니다. 새로운 수학 공식을 발견하거나, 분포 외(Out-of-distribution)의 문제를 풀 때는 GPT-5 Nano처럼 여기저기 찔러보는 '탐험(High Action)'이 필요합니다.

그래서 제가 생각하는 이상적인 미래 모델은 동적 스위칭이 가능한 형태라고 생각합니다.

 - 평소(탐험): LoRA를 끄고 넓은 평야를 탐색하며 창의적인 아이디어를 냅니다.
 - 실전(수렴): 코딩이나 의료 진단처럼 정확도가 필요하면, 특정 태스크에 과적합된 LoRA를 켜서 순식간에 골짜기로 밀어 넣습니다.

💡 마치며: 연금술에서 물리학으로

지금까지 우리는 프롬프트를 깎으며 왜 되는지 모르지만 잘 되네?라고 말하는 연금술사였습니다. 하지만 이 논문은 LLM의 행동을 '에너지', '작용', '평형'이라는 물리량으로 수치화했습니다.

하지만 주의할 점도 있습니다. 논문은 스스로를 "초기 탐색(Preliminary exploration)"이라 정의합니다. 실험은 제한된 모델과 환경에서 이루어졌으며, 저자들 역시 "과적합(Overfitting)된 모델은 이 물리 법칙을 따르지 않고 꼼수(Local Strategy)를 부릴 수 있다"고 경고합니다.

그럼에도 매우 유의미한 실험이라고 생각하고, 앞으로 좋은 모델을 만들기 위한 아주 중요한 힌트를 얻은 것 같습니다. 더 자세한 내용은 논문을 봐보시길 바랍니다.
110




