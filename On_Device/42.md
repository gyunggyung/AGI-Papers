---
id: 42
category: On_Device
title: 이전 글에서 국가대표 AI의 탈락 결과에 대해 다뤘습니다. 이번에는 조금 더 현실적인 이야기를 해볼까 합니다. 최근 NC AI가 산업 특화, 피지컬 AI 쪽에 집중한다고 발표했죠. 아주 현명한 전략이라고 봅니다. 우리 한국 모델들, 정말 많이 성장했고 멋집니다. 하지만 냉정하게 말해 GLM-4.7, MiniMax-M2.1 같은 중국의 최신 모델들과 정면 승부가 가능한 팀이 있나요? 딥시크는 신기술 논문을 쏟아내며 V4를 준비하고 있습니다.
---
이전 글에서 국가대표 AI의 탈락 결과에 대해 다뤘습니다. 이번에는 조금 더 현실적인 이야기를 해볼까 합니다. 최근 NC AI가 산업 특화, 피지컬 AI 쪽에 집중한다고 발표했죠. 아주 현명한 전략이라고 봅니다. 우리 한국 모델들, 정말 많이 성장했고 멋집니다. 하지만 냉정하게 말해 GLM-4.7, MiniMax-M2.1 같은 중국의 최신 모델들과 정면 승부가 가능한 팀이 있나요? 딥시크는 신기술 논문을 쏟아내며 V4를 준비하고 있습니다.

아이러니하게도 중국은 미국을 쫓고, 우리는 중국을 쫓습니다. 서로 비슷한 속도로 발전하니 그 거리가 좁혀지질 않습니다. 당장은 시간이 필요할 수도 있겠지만, 영원히 따라잡지 못할 수도 있다는 위기감도 듭니다.

그래서 우리는 전선을 바꿔야 할지도 모릅니다. 무조건 거대해지는 것이 아니라, NC처럼 뾰족해지는 것. 아예 도구 사용(Tool Use) 하나만 기가 막히게 잘하는 모델은 어떨까요?

오늘 소개할 논문은 바로 그 가능성을 증명합니다. 175B의 거대 모델(ChatGPT)을 350M짜리 초소형 모델로 압도하는 방법입니다. 아마존(AWS) 연구진이 발표한 논문입니다.


1. 다윗이 골리앗을 이기다: 77.55%(0.35B) vs 26.00%(175B)

대단한 수치입니다. 도구 사용 능력을 평가하는 'ToolBench'에서, 파라미터 3.5억 개(350M)짜리 모델이 1,750억 개(175B)로 추정되는 ChatGPT를 압도했습니다.

 - Our SLM (350M): 통과율 77.55%
 - ChatGPT-CoT (175B): 통과율 26.00%
 - ToolLLaMA (7B): 통과율 30.18%

단순히 비등한 게 아니라, 3배 가까운 성능 차이로 찍어 눌렀습니다. 그리고 20배 더 크고 특화 데이터로 학습한 7B 모델보다도 훨씬 잘합니다. 도구 호출(Tool Calling)이라는 특정 영역에서는 작은 것이 더 강할 수 있다는 것을 증명했습니다.

2. 도대체 Tool Calling이 왜 중요한가?

수치가 높은 건 알겠는데, 이게 왜 중요할까요? Tool Calling은 AI를 말쟁이에서 일꾼으로 바꿔주는 핵심 기능이기 때문입니다.

거대 모델이 아무리 똑똑해도 실시간 주식 정보를 모르고, 사내 DB를 조회할 수 없으면 그저 그럴싸한 텍스트 생성기에 불과합니다. 하지만 Tool Calling이 정확해지면 이야기가 달라집니다.

 - 실시간 재고 확인 후 주문 넣기
 - 복잡한 SQL 쿼리로 사내 데이터 분석하기

이 작은 모델은 챗봇이 아니라, 실제 세상의 API와 연결되어 업무를 자동화하는 에이전트의 손발이 됩니다. 77%의 통과율은 실무에 투입해도 에러 없이 돌아간다는 신뢰를 의미합니다.

3. 전략적 스위트 스폿 (Strategic Sweet Spot): 350M

저자들은 350M이 도구 사용을 위한 황금 비율이라고 주장합니다. 왜 더 큰 모델이 오히려 못할까요?

 - 파라미터 희석 (Parameter Dilution): 거대 모델은 너무 많은 걸 알고 있습니다. 소설도 써야 하고 철학도 논해야 하죠. 그래서 정작 API 규격에 맞춰 정확한 JSON을 뱉어야 할 때 딴생각을 하거나, 불필요하게 장황한 말을 늘어놓습니다.
 - 전문화 (Specialization): 반면 350M 모델은 용량이 작습니다. 이 작은 뇌를 오로지 도구를 선택하고 실행하는 로직으로만 꽉 채우니, 딴짓을 안 하고 시키는 일만 칼같이 수행하는 전문가가 됩니다.

4. 비결은 '생각하는 데이터' (The Power of CoT)

그럼 그냥 작은 모델을 쓰면 되냐? 아닙니다. 어떻게 가르치냐가 핵심입니다. 논문은 ToolBench 데이터셋 18만 개를 사용해 딱 1 에폭(Epoch)만 학습시켰습니다.

이 데이터에는 단순한 정답이 아닌 사고의 흐름(Chain of Thought)이 담겨 있습니다.


5. 가성비의 끝판왕 (Efficiency)

이 모델을 만드는 데 든 비용은 거대 모델 학습에 비하면 껌값 수준입니다.

 - 학습: Amazon SageMaker g5.8xlarge (A10G GPU 1장) 한 대만 있어도 몇 시간이면 끝납니다.
 - 추론: 350M 모델은 웬만한 노트북에서도 쌩쌩 돌아갑니다. 기업 입장에서 API 비용이나 서버 비용을 획기적으로 줄이면서도 성능은 더 뛰어난 에이전트를 도입할 수 있게 되는 겁니다.

6. 하지만 분명한 한계 (Limitations)

물론 만능은 아닙니다. 논문에서도 이 모델이 'ToolBench'라는 특정 벤치마크 평가 기준에 과적합(Overfitting)되었을 가능성을 인정합니다. 

통제된 테스트 환경을 벗어나, 복잡한 인증 과정이나 의존성이 얽혀 있는 실제 리얼월드 API(Real-world ecosystem)에서는 이만큼의 성능을 장담하기 어렵습니다. 또한 350M라는 작은 체급의 한계상, 도구 호출 이외의 복잡한 대화 맥락을 파악하는 능력은 여전히 부족할 수 있습니다.


마치며: 우리에게 필요한 건 '송곳'

중국과 미국의 거대 모델들이 우주 전쟁을 하고 있을 때, 우리는 그들이 놓치고 있는 틈새, 즉 작지만 치명적인(Small but Lethal) 모델을 만들어야 하지 않을까요?

모든 것을 다 잘하는 AI는 이제 빅테크의 영역입니다. 하지만 특정 도구를 기가 막히게 잘 다루는 350M 모델은 우리도 만들 수 있습니다. 덩치 큰 제너럴리스트보다, 날카로운 스페셜리스트가 필요한 시점입니다.

곧 아주 멋진 소식을 전해드리겠습니다. 기대해 주세요.

83




