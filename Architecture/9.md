---
id: 9
category: Architecture
title: Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation
---
"H100이 없으면 고성능 AI를 못 돌리나요?" 아니요! 소비자용 GPU(RTX 5090) 몇 장으로 구축한 '작은 모델들의 연합'이, 수천만 원짜리 장비가 필요한 거대 모델(100B+)을 이길 수 있습니다. 바로 'Mixture-of-Models (MoM)'입니다.

우리는 지금까지 "더 큰 모델(Scale)"이 정답이라고 믿었습니다. 하지만 이 논문은 "모델의 크기가 아니라, 모델을 연결하는 위상(Topology)이 지능을 결정한다"는 사실을 증명했습니다.

Mixture-of-Models 논문이 제시하는 5가지 핵심 디테일을 정리했습니다.

📄 제목: Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation
👥 저자: Tims Pecerskis et al. (Peeramid Labs)

1. 토폴로지가 스케일을 대체한다 (Topology > Scale)

기존의 방식(MoE, Chain of Agents)은 모델을 일렬로 세우거나(DAG), 단순히 섞는 데 그쳤습니다. 하지만 이 논문은 에이전트들의 대화를 거시적인 '순환 신경망(RNN)'처럼 설계했습니다.

 - 기존: 한 번 질문하고 답을 얻으면 끝 (단발성)
 - NSED: 합의에 도달할 때까지 반복 회의를 진행 (순환성)

마치 회의실에 갇힌 개발자들 같습니다. 1라운드에서 나온 답을 보고, 2라운드에서 다시 비판하고 수정합니다. 이 과정을 통해 20B 이하의 작은 모델들이 모여 100B급 모델의 추론 능력을 발휘합니다.

이걸 보면 살짝 Ralph Loop가 떠오릅니다.

2. 무신뢰 기반의 익명 코드 리뷰 (Trustless Consensus)

재밌는 점은 이 회의가 철저한 '익명'으로 진행된다는 겁니다.

 - 신원 은폐: 누가 쓴 답안인지 모르게 섞습니다. (작은 모델이 큰 모델 눈치를 보는 '아첨' 방지)
 - 대각 마스킹(Diagonal Mask): 자기 자신이 쓴 답안에는 투표할 수 없습니다. 점수를 따려면 남을 설득해야 합니다.
 - 결과: 이 가혹한 검증 시스템 덕분에, 안전성(Safety) 평가에서 아첨 지수가 단일 모델 대비 약 40% 정도 감소했습니다.

3. 하드웨어 아비트라지: 6천 달러로 6만 달러 이기기

우리들에게 가장 희소식인 부분입니다.

 - 기업용(Enterprise): 120B 모델을 돌리려면 H100 2장과 고가의 NVLink가 필요합니다. (비용 약 $60,000+)
 - NSED(Consumer): RTX 5090 3장에 각각 8B, 12B, 20B 모델을 띄워놓고 텍스트만 주고받습니다. (비용 약 $6,000)

결과는? 수학 벤치마크(AIME 2025)에서 소비자용 앙상블(84.0%)이 딥마인드나 딥시크의 기업용 모델들과 대등하거나 더 높은 점수를 기록했습니다. 비싼 대역폭(NVLink) 대신, 느리지만 확실한 '생각의 시간(Latency)'을 투입해 가성비의 기적을 만든 셈입니다.

4. 멍청한 다수 vs 똑똑한 소수 (브로커의 역할)

그렇다면 아무 모델이나 섞으면 될까요? 실험 결과 검증 정확도가 '찍기 수준(50% 이하)'에 불과한 모델은 검증 능력이 떨어져 오히려 '노이즈'가 되었습니다.

여기서 'Dynamic Expertise Broker'라는 개념이 등장합니다.

 - 브로커(소장님): 사용자의 질문 난이도와 예산을 보고, "이번엔 창의적인 20B 모델 하나랑, 깐깐한 12B 검증자 둘을 붙여"라고 팀을 짜줍니다.
 - 최적화: 단순히 모델을 많이 쓰는 게 아니라, 배낭 문제(Knapsack Problem)를 풀듯 가성비 최적의 팀을 런타임에 구성합니다.

5. 큰 모델끼리 뭉치거나, 같은 모델을 여러 개 쓰면요?

더 비효율적이고, 결과가 별로 안 좋습니다.

 - 거대 모델 팀 (High-Performance): 너무 똑똑하고 예의 바른(RLHF) 모델들은 서로 "네 말이 맞습니다"라며 아첨(Sycophancy)하기 바빴습니다. 서로 비판을 안 하니 성능 향상이 금방 멈춰버렸습니다.

 - 복제 모델 팀 (Homogenous): 똑같은 모델 3개를 썼더니 집단 사고(Groupthink)에 빠졌습니다. 생각하는 방식이 같아서 한 명이 틀리면 다 같이 틀립니다.

 - 교훈: 성능의 핵심은 '다양성(Heterogeneity)'입니다. 인간 사회처럼, 서로 다른 배경을 가진 모델들이 치열하게 토론할 때(Discord), 비로소 정답(Discovery)이 튀어나옵니다.

💡 마치며: 더 큰 웨이트보다 더 나은 회로를


vLLM의 프리픽스 캐싱(Prefix Caching) 덕분에 반복되는 회의 내용은 메모리에 상주하고, 우리는 그저 "생각하는 시간"을 조금 더 투자하면 됩니다.

5분 동안 깊게 고민한 대학생 3명이, 1초 만에 대답하는 교수님 1명을 이길 수도 있는 곳. 그것이 바로 추론 시간 컴퓨팅(Inference-Time Compute)의 매력 아닐까요?




likesupport
71




