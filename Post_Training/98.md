---
id: 98
category: Post_Training
title: Gemma 3 모델의 핵심 목표 및 특징
---
Gemma 3 모델의 핵심 목표 및 특징

Gemma 3 모델은 구글 딥마인드에서 개발한 최신 멀티모달(Multimodal) 오픈 언어 모델입니다. 이전 Gemma 2 모델 대비 성능 향상과 다양한 기능 확장에 중점을 두었으며, 특히 다음과 같은 핵심 특징을 포함하고 있습니다.

멀티모달 및 긴 문맥 이해


최대 128,000개 토큰의 긴 문맥 처리를 지원하며, 이는 기존 대비 훨씬 긴 맥락을 효율적으로 다룰 수 있도록 모델 구조를 최적화한 덕분입니다.

긴 문맥을 효율적으로 처리하기 위해 KV 캐시의 메모리 사용량을 줄이는 아키텍처 변경(로컬 및 글로벌 어텐션 비율을 5:1로 구성하고 로컬 어텐션의 길이를 1024 토큰으로 제한)을 적용했습니다.


다국어 능력 향상

훈련 데이터 구성에 있어서 다양한 언어의 균형을 개선하여 다국어 성능을 크게 끌어올렸습니다.


수학 및 추론 능력 강화

수학 문제, 논리적 추론, 명령어 처리 능력 향상을 위한 특수 포스트-트레이닝 기법(지식 증류 및 RL 미세 조정)을 사용했습니다.




---

2. 아키텍처와 훈련 방식

모델 크기

모델은 1B부터 최대 27B의 크기로 제공되며, 대부분 소비자용 GPU나 스마트폰 등 일반적인 하드웨어에서 작동할 수 있도록 경량화된 형태로 구성되었습니다.


시각 인코더(Vision Encoder)



프리트레이닝(Pre-training)

Gemma 2 모델과 비슷한 방식이지만, 데이터의 양과 다국어 균형을 더 정밀하게 조정하여 성능을 높였습니다.

지식 증류 기법을 사용하여 더 큰 모델(teacher 모델)의 성능을 더 작은 모델(student 모델)에 효과적으로 전이했습니다.


포스트-트레이닝(Post-training, Instruction Tuning)

IT(Instruction Tuned) 모델을 만들기 위해 강화학습 기반 미세조정(RLHF), 인간 피드백을 활용한 보상 모델(WARP, WARM, BOND 등)을 적용하여 명령어 처리 성능을 대폭 높였습니다.

미세 조정 과정에서 유해한 데이터나 개인 정보를 효과적으로 제거하여 안전성을 강화했습니다.




---

3. 성능 평가 및 주요 성과

모델 성능

Gemma3 27B-IT 모델의 경우 기존 Gemma2 27B 모델을 큰 차이로 능가했고, 특히 수학(MATH), 논리 추론(GPQA Diamond), 코딩(LiveCodeBench) 및 다국어(Global MMLU) 벤치마크에서 뛰어난 성능 향상을 보였습니다.

Gemma3 27B-IT는 Elo 점수 1338을 기록하며, 유사 규모의 모델들(Qwen2.5 72B, Llama3 405B 등)보다 뛰어난 성과를 나타내, 사이즈 대비 매우 효율적인 성능을 보이고 있습니다.


긴 컨텍스트 처리 능력 향상

긴 문맥 처리를 위한 로컬/글로벌 어텐션 비율을 5:1로 설정하고 슬라이딩 윈도우를 1024로 제한했음에도 불구하고, 성능 감소 없이 매우 효과적으로 긴 문맥을 처리할 수 있게 되었습니다.







---

4. 모델 경량화와 양자화(Quantization)

Quantization Aware Training(QAT)을 사용하여 INT4, SFP8 등 양자화 형식으로 제공되어 모델 크기를 최소화하고 소비자 기기에서도 효율적인 추론이 가능하도록 했습니다.



---

5. 데이터 보안 및 프라이버시

메모리제이션(Memorization) 문제에 대한 강력한 대응책을 적용하여, Gemma 3는 기존 모델 대비 데이터 암기율이 매우 낮아 프라이버시 측면에서 더 안전하다는 평가를 받았습니다.



---

6. 안전성과 책임성 관리

데이터 수집부터 모델 배포까지 전 과정에서 철저한 안전성 및 보안 평가를 수행하여, 유해 콘텐츠 생성 방지, 개인 정보 보호, 의료 정보 신뢰성 유지 등 엄격한 안전 기준을 준수했습니다.



---

요약 및 결론


HF: https://lnkd.in/gpDbTCJA

22




