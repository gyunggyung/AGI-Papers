# ğŸš€ AGI-Papers

![AGI-Papers](https://img.shields.io/badge/AGI--Papers-2026-blue?style=for-the-badge&logo=github)
![Topic](https://img.shields.io/badge/Topic-AGI%20%7C%20Agents%20%7C%20Trends-green?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Active-important?style=for-the-badge)

> **Toward Artificial General Intelligence (AGI) in 2026.**  
> A curated archive of breakthroughs in **Agents**, **Architecture**, **Training**, **RAG**, and **On-Device AI**.

## ğŸ“Œ Introduction

2026ë…„, AGIì— ê·¸ ì–´ëŠ ë•Œë³´ë‹¤ ê°€ê¹Œìš´ ì‹œëŒ€ê°€ ë„ë˜í–ˆìŠµë‹ˆë‹¤.  
ì´ ì €ì¥ì†ŒëŠ” **AGI(Artificial General Intelligence)** ë¡œ í–¥í•˜ëŠ” ì—¬ì •ì—ì„œ ì¤‘ìš”í•œ ë…¼ë¬¸ë“¤ì„ ë¦¬ë·°í•˜ê³  ì•„ì¹´ì´ë¹™í•˜ëŠ” ê³µê°„ì…ë‹ˆë‹¤.

ì£¼ë¡œ ì œ **[LinkedIn](https://www.linkedin.com/in/kiwoong-yeom/)** ì—ì„œ ë‹¤ë£¬ ë…¼ë¬¸ë“¤ì— ëŒ€í•œ ì‹¬ë„ ìˆëŠ” ë¦¬ë·°ê°€ ì—…ë¡œë“œë˜ë©°, ë•Œë¡œëŠ” ì†Œì…œ ë¯¸ë””ì–´ì— ê³µìœ í•˜ê¸° ì „ì˜ **Pre-release ì¸ì‚¬ì´íŠ¸**ë‚˜ ë‚ ê²ƒì˜ ìƒê°ë“¤ì´ ì´ê³³ì— ë¨¼ì € ê¸°ë¡ë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ“‚ Archives

ê³¼ê±°ì— ì •ë¦¬í–ˆë˜ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ëŠ” ì•„ë˜ ë§í¬ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ğŸ‘‰ **[Past AGI-Papers (Pre-2026)](Pre-README.md)**

---

## ğŸ“š Contents

ì´ ì €ì¥ì†ŒëŠ” AGIë¥¼ í–¥í•œ ì—¬ì •ì„ ë‹¤ìŒ 8ê°€ì§€ í•µì‹¬ ì£¼ì œë¡œ ë¶„ë¥˜í•˜ì—¬ ì •ë¦¬í•©ë‹ˆë‹¤.

- [ğŸ¤– Agents](#agents) : ììœ¨ ì—ì´ì „íŠ¸, í–‰ë™/ê³„íš(Planning) ëª¨ë¸, í”„ë ˆì„ì›Œí¬
- [ğŸ§  Architecture](#architecture) : LLM ì•„í‚¤í…ì²˜ í˜ì‹  (Transformer, Mamba, MoE)
- [ğŸ“š Pre-Training](#pre-training) : í•™ìŠµ ë°ì´í„°, ìŠ¤ì¼€ì¼ë§ ë²•ì¹™, íŒŒìš´ë°ì´ì…˜ ëª¨ë¸
- [ğŸ¯ Post-Training](#post-training) : RLHF, DPO, GRPO, ì •ë ¬(Alignment)
- [ğŸ—‚ï¸ RAG & Knowledge](#rag--knowledge) : ê²€ìƒ‰ ì¦ê°• ìƒì„±, ì§€ì‹ ê·¸ë˜í”„, ë©”ëª¨ë¦¬
- [ğŸ’» On-Device AI](#on-device-ai) : ë¡œì»¬ êµ¬ë™, ì—£ì§€ ì»´í“¨íŒ…, ìµœì í™”
- [ğŸš€ Projects](#projects) : ì§ì ‘ êµ¬í˜„í•œ í”„ë¡œì íŠ¸ ë° ì‹¤í—˜ ê²°ê³¼
- [ğŸ”¥ Trends & Industry](#trends--industry) : AI ì‚°ì—…ì˜ ë™í–¥, ì¸ì‚¬ì´íŠ¸, ì£¼ìš” ë‰´ìŠ¤

---

## <a id="agents"></a>ğŸ¤– Agents

*   [**Adaptation of Agentic AI**](./Agents/80.md)  
    *ê±°ëŒ€ ëª¨ë¸ íŠœë‹ë³´ë‹¤ ë„êµ¬ íŠœë‹ì´ íš¨ìœ¨ì ì¸ ì´ìœ  (T2 > A2).*
*   [**Memory in the Age of AI Agents**](./Agents/77.md)  
    *ì—ì´ì „íŠ¸ ê¸°ì–µì˜ í˜•íƒœ, ê¸°ëŠ¥, ì—­ë™ì„±ì— ëŒ€í•œ ê³ ì°°.*
*   [**World Models Research**](./Agents/11.md)  
    *World Knowledge Injection vs Specific Tasks.*
*   [**Mixture-of-Models**](./Agents/9.md)  
    *Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation.*
*   [**AIRS-Bench**](./Agents/5.md)  
    *Frontier AI Research Science Agentsë¥¼ ìœ„í•œ íƒœìŠ¤í¬.*
*   [**OctoTools**](./Agents/99.md)  
    *Training-free LLM Agent Framework.*
*   [**Chain-of-Draft(CoD)**](./Agents/93.md)  
    *CoTì˜ ì¥ì ì„ ìœ ì§€í•˜ë©´ì„œ í† í° ì‚¬ìš©ëŸ‰ê³¼ ê³„ì‚° ë¹„ìš©ì„ ì¤„ì´ëŠ” íšê¸°ì ì¸ ì ‘ê·¼ë²•.*

## <a id="architecture"></a>ğŸ§  Architecture

*   [**LLMì˜ "ì…ë ¥ ê¸¸ì´ ì œê³±(N^2)"ì˜ ì €ì£¼**](./Architecture/90.md)  
    *ëˆ„ê°€ ë¨¼ì € ëŠì–´ë‚¼ ê²ƒì¸ê°€?*
*   [**Mistral Large 3: íš¨ìœ¨ì„±ì˜ ê·¹ëŒ€í™”**](./Architecture/88.md)  
    *Mistral Large 3 vs Kimi K2: Efficiency vs Scale.*
*   [**í‘œì¤€ì´ ëœ V3 ì•„í‚¤í…ì²˜**](./Architecture/86.md)  
    *Mistral Large 3, Kimi K2 ê·¸ë¦¬ê³  DeepSeek V3.2 ë¶„ì„.*
*   [**Ai2 Olmo 3**](./Architecture/85.md)  
    *ì„±ëŠ¥ë³´ë‹¤ëŠ” ê³¼ì •ì˜ íˆ¬ëª…ì„±ì— ì§‘ì¤‘í•œ LLM ì—°êµ¬ì˜ êµê³¼ì„œ.*
*   [**Liquid AI LFM2-2.6B-Exp íŠœë‹ê¸°**](./Architecture/58.md)  
    *ë…¼ë¬¸ Related Work ì„¹ì…˜ì„ í†µì§¸ë¡œ ìƒì„±í•˜ëŠ” ë„êµ¬ ì œì‘.*
*   [**Nemotron-3-Nano-30B-A3B**](./Architecture/50.md)  
    *Qwen3ë³´ë‹¤ ë¹ ë¥´ê³  ê°•ë ¥í•œ Mamba-2 í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸.*
*   [**DeepSeek Engram**](./Architecture/44.md)  
    *ê¸°ì–µì„ íš¨ìœ¨í™”í•˜ì—¬ ì—°ì‚° ë‚­ë¹„ë¥¼ ì¤„ì´ëŠ” ìƒˆë¡œìš´ í¬ì†Œì„± ì¶•.*
*   [**2026ë…„ì˜ í†µë… íŒŒê´´: 90M, 600M ëª¨ë¸**](./Architecture/41.md)  
    *ì´ˆì†Œí˜• ëª¨ë¸ë“¤ì˜ ë†€ë¼ìš´ ì§€ì‹œ ì´í–‰ ëŠ¥ë ¥.*
*   [**Sakana AI RePo**](./Architecture/38.md)  
    *ìœ„ì¹˜ ì •ë³´ë¥¼ ì¬ì„¤ê³„(Re-position)í•˜ë¼.*
*   [**DeepSeek vs Qwen (A3B MoE)**](./Architecture/35.md)  
    *ì •ë°˜ëŒ€ì˜ ì„¤ê³„ ì² í•™ ë¶„ì„.*
*   [**Pau Labarta Bajo's Insight**](./Architecture/27.md)  
    *ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸.*
*   [**Generative Modeling via Drifting**](./Architecture/6.md)  
    *í™•ì‚° ëª¨ë¸ì˜ 250ë‹¨ê³„ë¥¼ ë‹¨ 1ë‹¨ê³„(1-step)ë¡œ ì¤„ì—¬ ì†ë„ì™€ í’ˆì§ˆì„ ë™ì‹œì— ì¡ì€ í˜ì‹ .*

## <a id="pre-training"></a>ğŸ“š Pre-Training

*   [**LLM í•™ìŠµ íš¨ìœ¨í™” ë°©ì•ˆ: ì¸ê°„ì˜ ì–¸ì–´ ìŠµë“ ë°©ì‹**](./Pre_Training/97.md)  
    *ì¸ê°„ì˜ ì–¸ì–´ ìŠµë“ ë°©ì‹ì„ ëª¨ë°©í•œ ì ì§„ì  ì–´íœ˜ í•™ìŠµë²•(Vocabulary Curriculum Learning).*
*   [**Diffusion LLM (100B Parameters)**](./Pre_Training/83.md)  
    *30B ëª¨ë¸ë³´ë‹¤ 2ë°° ë¹ ë¥¸ ë³‘ë ¬ ìƒì„± ëª¨ë¸ì˜ ë“±ì¥.*
*   [**RoPEê°€ ì •ë³´ë¥¼ ìœ ì‹¤í•˜ê³  ìˆë‹¤?**](./Pre_Training/79.md)  
    *í‘¸ë‹¨ëŒ€ ì—°êµ¬ì§„ì˜ ì¶©ê²©ì ì¸ ë°œê²¬ê³¼ í•´ê²°ì±….*
*   [**Python ì¬ê·€ë¡œ ì‹œì‘í•˜ëŠ” 1,000ë§Œ í† í° ì‹œëŒ€**](./Pre_Training/60.md)  
    *Recursive Language Models: Python ì¬ê·€ë¡œ 1,000ë§Œ í† í° ì²˜ë¦¬í•˜ê¸°.*
*   [**Solar Openì˜ GLM í‘œì ˆ ë…¼ë€ ì¢…ê²°**](./Pre_Training/56.md)  
    *From Scratch ê°œë°œì˜ ì¹˜ì—´í•œ í”ì .*
*   [**Sakana AI: ìœ„ì¹˜ ì •ë³´(Positional Embeddings)ëŠ” ë²„ë ¤ë¼**](./Pre_Training/47.md)  
    *DroPE: í•™ìŠµí•  ë•Œë§Œ ìœ„ì¹˜ ì •ë³´ë¥¼ ì“°ê³  ì‹¤ì „ì—ì„œëŠ” ë²„ë¦¬ëŠ” ëº„ì…ˆì˜ ë¯¸í•™.*
*   [**CALM: Continuous Autoregressive Language Models**](./Pre_Training/34.md)  
    *í•œ ê¸€ìì”© íƒ€ì´í•‘í•˜ëŠ” LLMì„ ë„˜ì–´, 4ê°œì”© ìƒì„±í•˜ëŠ” ì—°ì† ë²¡í„° ì˜ˆì¸¡.*
*   [**Beyond Transformers 2**](./Pre_Training/13.md)  
    *ë©ì¹˜ ê²½ìŸì„ ë„˜ì–´ ìƒê°ê³¼ ë³¸ì§ˆë¡œ.*
*   [**What LLMs Think When You Don't Tell Them?**](./Pre_Training/4.md)  
    *ì•„ë¬´ëŸ° ì§€ì‹œë„ í•˜ì§€ ì•Šì•˜ì„ ë•Œ LLMì€ ë¬´ì—‡ì„ ìƒê°í•˜ëŠ”ê°€? ëª¨ë¸ ì„±ê²© ìœ í˜• ë¶„ì„.*

## <a id="post-training"></a>ğŸ¯ Post-Training

*   [**Gemma 3 ëª¨ë¸ì˜ í•µì‹¬ ëª©í‘œ ë° íŠ¹ì§•**](./Post_Training/98.md)  
    *êµ¬ê¸€ ë”¥ë§ˆì¸ë“œì˜ ìµœì‹  ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ë¶„ì„.*
*   [**Emergent Misalignment**](./Post_Training/96.md)  
    *ì·¨ì•½í•œ ì½”ë“œë¥¼ ë°°ìš´ AIì˜ ìœ„í—˜í•œ ì¼íƒˆ.*
*   [**Stabilizing RL with LLMs**](./Post_Training/92.md)  
    *í™”ë ¤í•œ ê¸°êµë³´ë‹¤ ìˆ˜í•™ì  ê¸°ë³¸ê¸°ê°€ ì¤‘ìš”í•œ ì´ìœ .*
*   [**LFM2 1.2B ê¸°ë°˜ í•œêµ­ì–´-ì˜ì–´ ë²ˆì—­ê¸°**](./Post_Training/89.md)  
    *LFM2 1.2B ëª¨ë¸ë¡œ êµ¬ê¸€ê³¼ ì•Œë¦¬ë°”ë°”ì˜ 4B ëª¨ë¸ì„ ì´ê¸´ ë²ˆì—­ê¸° ì œì‘ê¸°.*
*   [**LFM2 ë²ˆì—­ê¸° ê°œë°œê¸°: í•µì‹¬ ë°œê²¬ ë° ì„±ê³¼**](./Post_Training/82.md)  
    *SFTì™€ RLì˜ ì„±ëŠ¥ ì°¨ì´ ë¶„ì„ ë° Liquid AI ê³µì‹ ì¿¡ë¶ ë“±ì¬ ì†Œì‹.*
*   [**Small Language Model for Translation**](./Post_Training/81.md)  
    *Advice for AI engineers.*
*   [**Yann LeCun: World Modelì˜ ì¤‘ìš”ì„±**](./Post_Training/78.md)  
    *LLMì€ ë¬¼ë¦¬ ì„¸ê³„ë¥¼ ë°°ìš¸ ìˆ˜ ì—†ë‹¤?*
*   [**Liquid AI LFM2-1.2B íŠœë‹ ì‹¤íŒ¨ê¸°**](./Post_Training/76.md)  
    *í•œêµ­ì–´-ì˜ì–´ ë²ˆì—­ RL(GRPO) í•™ìŠµ ì‹¤íŒ¨ì™€ êµí›ˆ.*
*   [**Sebastian Raschka, PhD: "Ahead of AI"**](./Post_Training/59.md)  
    *ê¸°ë³¸ê¸°ë¶€í„° ìµœì‹  íŠ¸ë Œë“œê¹Œì§€.*
*   [**í•œêµ­ì–´ LLM í•™ìŠµ ë°ì´í„°ì˜ ë¶€ì¬**](./Post_Training/51.md)  
    *Pre-trainingë¶€í„° GRPOê¹Œì§€ì˜ í—˜ë‚œí•œ ì—¬ì •.*
*   [**Anthropicì˜ ìƒíƒœê³„ ì¡°ì´ê¸°**](./Post_Training/49.md)  
    *OpenCode ì°¨ë‹¨ê³¼ Claude Code ì‚¬ìš©ëŸ‰ ì œí•œì˜ ì•„ì‰¬ì›€.*
*   [**GDPO: Multi-reward RL**](./Post_Training/46.md)  
    *GRPOì˜ ì•½ì ì„ ê·¹ë³µí•œ ìƒˆë¡œìš´ ê°•í™”í•™ìŠµ ê¸°ë²•.*
*   [**Detailed balance in LLM-driven agents**](./Post_Training/23.md)  
    *LLMì´ ë¬¼ë¦¬í•™ì˜ 'ìµœì†Œ ì‘ìš©ì˜ ì›ë¦¬'ë¥¼ ë”°ë¥¸ë‹¤ëŠ” ê²ƒì„ ì¦ëª…í•œ ì—°êµ¬.*
*   [**AI ê±°í’ˆë¡ ì˜ ë³¸ì§ˆ**](./Post_Training/2.md)  
    *ì‹œì¥ ì¶•ì†Œê°€ ì•„ë‹Œ ìˆ˜ê¸‰ ì•ˆì •í™”ì™€ ì‚°ì—…ì˜ ì„±ìˆ™.*
*   [**iGRPO**](./Post_Training/1.md)  
    *Self-Feedback-Driven LLM Reasoning: ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ë§Œë“  ì´ˆì•ˆì„ ë³´ê³  ë°°ìš°ëŠ” ìê°€ ê°œì„  ê°•í™”í•™ìŠµ.*

## <a id="rag--knowledge"></a>ğŸ—‚ï¸ RAG & Knowledge

*   [**HippoRAG 2**](./RAG/100.md)  
    *ì¸ê°„ì˜ ê¸°ì–µ ë©”ì»¤ë‹ˆì¦˜ì„ ëª¨ë°©í•œ ë¹„ëª¨ìˆ˜ì  ì—°ì† í•™ìŠµ (Bio-inspired Continual Learning).*
*   [**DeepSeek-V3 vs V3.2: ì•„í‚¤í…ì²˜ì˜ ì§„í™”**](./RAG/94.md)  
    *ì•„í‚¤í…ì²˜ì˜ ì§„í™”ì™€ ê¸°ìˆ ì  ëª©í‘œì .*
*   [**From Code Foundation Models to Agents**](./RAG/84.md)  
    *Code Foundation Modelì—ì„œ ììœ¨ ì½”ë”© ì—ì´ì „íŠ¸ë¡œì˜ ì§„í™” ì²­ì‚¬ì§„.*
*   [**ADR-Bench ì „ë¬¸ê°€ í‰ê°€**](./RAG/55.md)  
    *DeepSeek-v3.2ë¥¼ ì••ë„í•œ íš¨ìœ¨ì ì¸ ì—ì´ì „íŠ¸ ëª¨ë¸.*
*   [**vLLMì˜ ìŠ¹ë¦¬: ì••ë„ì ì¸ ì†ë„**](./RAG/29.md)  
    *í‘œì¤€ì´ ë˜ê¸°ê¹Œì§€.*
*   [**RAG & Agent Memory 4ì„ **](./RAG/10.md)  
    *GraphSearch, S-RAG, xMemory ë“± ìµœì‹  ë…¼ë¬¸ ì†Œê°œ.*

## <a id="on-device-ai"></a>ğŸ’» On-Device AI

*   [**Liquid AI 1.2B vs Google 4B**](./On_Device/45.md)  
    *Pau Labarta Bajo's Local AI Insight.*
*   [**êµ­ê°€ëŒ€í‘œ AI íƒˆë½ ê·¸ í›„ (On-Device Focus)**](./On_Device/42.md)  
    *í˜„ì‹¤ì ì¸ ì§„ë‹¨ê³¼ ì¤‘êµ­ ëª¨ë¸ê³¼ì˜ ë¹„êµ.*
*   [**ë¡œì»¬ LLM êµ¬ë™ì˜ 6ê°€ì§€ í˜„ì‹¤ì  ë°©ë²•**](./On_Device/33.md)  
    *STEM: ë‹¨ìˆœíˆ ì§€ì‹ì„ êº¼ë‚´ê¸° ìœ„í•´ ë¹„ì‹¼ GPUë¥¼ ì“°ì§€ ë§ì.*
*   [**LLM ì§€ëŠ¥ì˜ ë¯¼ë‚¯ê³¼ í•œê³„**](./On_Device/3.md)  
    *ë²¤ì¹˜ë§ˆí¬ëŠ” ìˆ˜ì„ì´ì§€ë§Œ í˜„ì¥(ì§„ë£Œ)ì—ì„œëŠ” ë‚™ì œì¸ ì´ìœ ì™€ í•´ê²°ì±….*

## <a id="projects"></a>ğŸš€ Projects

### ğŸ¤– Autonomous Agents
*   [**Gemini-Claw ê°œë°œê¸°**](./Projects/20.md)  
    *2ì‹œê°„ ë§Œì— ë§Œë“ , ìŠ¤ìŠ¤ë¡œ ì½”ë“œë¥¼ ì§œê³  ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì—ì´ì „íŠ¸.*
*   [**ìŠ¤ìŠ¤ë¡œ ì›¹í˜ì´ì§€ë¥¼ ë§Œë“¤ê³  ê²€ì¦í•˜ëŠ” AI**](./Projects/16.md)  
    *Gemini-Claw: ìŠ¤ìŠ¤ë¡œ ì›¹í˜ì´ì§€ë¥¼ ë§Œë“¤ê³ , ì‹¤í–‰í•˜ê³ , ê²€ì¦ê¹Œì§€ í•˜ëŠ” ì—ì´ì „íŠ¸.*
*   [**Insight Agents**](./Projects/21.md)  
    *An LLM-Based Multi-Agent System for Data Insights.*
*   [**SEAL: ìŠ¤ìŠ¤ë¡œ Fine-tuningí•˜ëŠ” ì—ì´ì „íŠ¸**](./Projects/26.md)  
    *ê°€ëŠ¥ì„±ê³¼ í•œê³„.*

### ğŸ› ï¸ Coding & Dev Tools
*   [**Claube Vibe Coding**](./Projects/52.md)  
    *ë³µì¡í•œ ë°±ì—”ë“œëŠ” AIì—ê²Œ ë§¡ê¸°ê³  ê³µì›ì—ì„œ ëŸ¬ë‹í•˜ê¸°.*
*   [**ë¬´í•œ ë£¨í”„ ë°”ì´ë¸Œ ì½”ë”©**](./Projects/22.md)  
    *"í…ŒìŠ¤íŠ¸ ì„±ê³µí•  ë•Œê¹Œì§€ ê³„ì†í•´" í•œë§ˆë””ë¡œ ê°œë°œ ëë‚´ê¸°.*
*   [**Docling-Translate**](./Projects/91.md)  
    *CLIì˜ ë²ˆê±°ë¡œì›€ì„ í•´ê²°í•œ Streamlit ê¸°ë°˜ ë²ˆì—­ ë„êµ¬.*
*   [**LFM-Scholar**](./Projects/57.md)  
    *ë…¼ë¬¸ Related Work ìë™ ì‘ì„±ì„ ìœ„í•œ LLM ë„êµ¬.*
*   [**Gemini-Claw íŒŒì¼ ì¡°ì‘ ê¸°ëŠ¥**](./Projects/19.md)  
    *"í„°ë¯¸ë„ ì¡°ì‘ ê¸°ëŠ¥ì´ë‚˜ ë„£ì–´ë³¼ê¹Œ?"*
*   [**Gemini-Claw ì˜¤í”¼ìŠ¤ ìƒì„±**](./Projects/15.md)  
    *ë¡œì»¬ í´ë”ë¥¼ ë¶„ì„í•´ 94ì´ˆ ë§Œì— í’€ íŒ¨í‚¤ì§€ ìƒì„±.*
*   [**Gemini 3 Pro + ë‚¯ì„  API**](./Projects/18.md)  
    *ê¸°ëŒ€ ì´ìƒì˜ ì½”ë“œ í€„ë¦¬í‹°ì™€ ì¬ë¯¸.*

### ğŸ’» On-Device AI
*   [**Tiny MoA**](./Projects/32.md)  
    *ì‹œê°„ë‹¹ $100 íƒœìš°ëŠ” AI vs CPUë¡œ ëŒë¦¬ëŠ” ê°€ì„±ë¹„ ë©€í‹° ì—ì´ì „íŠ¸.*
*   [**Tiny MoA Tool Calling**](./Projects/30.md)  
    *16GB ë…¸íŠ¸ë¶ì—ì„œ êµ¬í˜„í•œ ë¡œì»¬ ì—ì´ì „íŠ¸ì˜ ëˆˆê³¼ ì†.*
*   [**Tiny MoA: ì§„ì •í•œ ì˜¨ë””ë°”ì´ìŠ¤ AI**](./Projects/24.md)  
    *Clawdbot is cool, but Tiny MoA runs on CPU.*
*   [**Clawdbot vs ë¡œì»¬ AI**](./Projects/25.md)  
    *API ì—†ëŠ” ì§„ì •í•œ ì˜¨ë””ë°”ì´ìŠ¤ AIë¥¼ í–¥í•˜ì—¬.*
*   [**vLLM & SGLang in llama.cpp**](./Projects/28.md)  
    *CPU ì¶”ë¡  ì†ë„ 1.8ë°° í–¥ìƒ.*

### ğŸ§  Model Experiments
*   [**HybriKo: í•˜ì´ë¸Œë¦¬ë“œ RNN+Attention**](./Projects/54.md)  
    *Google Griffinê³¼ Liquid AI LFM2ì—ì„œ ì˜ê°ì„ ë°›ì€ ì•„í‚¤í…ì²˜.*
*   [**HybriKo-117M**](./Projects/37.md)  
    *A100 8ì¥ìœ¼ë¡œ ë§Œë“  ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´ Function Calling ëª¨ë¸.*
*   [**HybriKo-117M-LinuxFC**](./Projects/36.md)  
    *í•œêµ­ì–´ë¥¼ ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´ë¡œ ë°”ê¿”ì£¼ëŠ” ì´ˆê²½ëŸ‰ ëª¨ë¸ ê°œë°œê¸°.*
*   [**52-Layer HybriKo-430M**](./Projects/31.md)  
    *T4 GPU í•˜ë‚˜ì— ìµœì‹  ì•„í‚¤í…ì²˜ë¥¼ ìš°ê²¨ë„£ì€ ì‹¤í—˜ì‘.*
*   [**1.2B ëª¨ë¸ë¡œ PPT ë§Œë“¤ê¸°**](./Projects/8.md)  
    *ì†Œí˜• ëª¨ë¸ì˜ ê°€ëŠ¥ì„±.*
*   [**GPT êµ¬ì¡°ì˜ í•œê³„ë¥¼ ë„˜ì–´**](./Projects/14.md)  
    *Liquid AI, TII, NVIDIAì˜ ìƒˆë¡œìš´ ì‹œë„ë“¤.*

### ğŸ’­ Insights & Essays
*   [**ìµœê·¼ êµ¬í˜„í•œ AI í”„ë¡œì íŠ¸ ë° ì„±ê³¼**](./Projects/7.md)  
    *Gemini-Clawë¡œ êµ¬í˜„í•œ ë§¥í‚¨ì§€ ìŠ¤íƒ€ì¼ ë³´ê³ ì„œ ë° PPT ìë™ ìƒì„±.*
*   [**Gemini-Claw ì„±ëŠ¥ vs ë³´ì•ˆ**](./Projects/12.md)  
    *LLM ì—ì´ì „íŠ¸ì˜ ìœ„í—˜í•œ ì ì¬ë ¥.*
*   [**AIì— ëŒ€í•œ ë‘ë ¤ì›€ vs í¥ë¯¸**](./Projects/17.md)  
    *OpenClaw, í™˜ê° ì¸ìš©, Vibe Coding í˜„ìƒì— ëŒ€í•œ ë‹¨ìƒ.*

## <a id="trends--industry"></a>ğŸ”¥ Trends & Industry

*   [**Hugging Face CEOì˜ í•œêµ­ AI ëª¨ë¸ ì‘ì›**](./Trends/53.md)  
    *SKT A.X, LG AI, Upstage ë“± í•œêµ­ ëª¨ë¸ì˜ ì „ì„±ì‹œëŒ€.*
*   [**CES 2026: AMD Lisa Suì™€ Liquid AI**](./Trends/48.md)  
    *AMDê°€ ì„ íƒí•œ íŒŒíŠ¸ë„ˆ.*
*   [**êµ­ê°€ëŒ€í‘œ AI í”„ë¡œì íŠ¸ 1ì°¨ ê²°ê³¼**](./Trends/43.md)  
    *LG, SKT, Upstage ì„ ë°œê³¼ íƒˆë½ ê¸°ì—…ë“¤ì˜ í–‰ë³´.*
*   [**Post-trainingì˜ í•œê³„**](./Trends/40.md)  
    *ì™œ ëª¨ë¸ì€ í•™ìŠµì´ ëë‚˜ë©´ ë” ì´ìƒ ë˜‘ë˜‘í•´ì§€ì§€ ì•ŠëŠ”ê°€?*
*   [**LLM ê°œë°œê³¼ ì‚¬ë‚´ ì •ì¹˜**](./Trends/39.md)  
    *ì‹¤ë¬´ì vs ê²½ì˜ì§„ì˜ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê´€ì  ì°¨ì´.*

---

## ğŸ“¬ Connect

*   [<img src="https://img.shields.io/badge/LinkedIn-Kiwoong Yeom-blue?style=flat&logo=linkedin&logoColor=white" />](https://www.linkedin.com/in/kiwoong-yeom) [<img src="https://img.shields.io/badge/GitHub-gyunggyung-black?style=flat&logo=github&logoColor=white" />](https://github.com/gyunggyung)
*   ğŸ“§ **Contact:** newhiwoong@gmail.com

---
*Disclaimer: The views and opinions expressed in these reviews are those of the author and do not necessarily reflect the official policy or position of any other agency, organization, employer or company.*
