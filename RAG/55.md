---
id: 55
category: RAG
title: 놀라운 점은 그 효율성입니다. 자체 벤치마크인 ADR-Bench의 전문가 평가에서, 이 모델은 DeepSeek-v3.2나 GLM-4.6 같은 거대 모델들을 압도적인 Elo 점수 차로 따돌렸습니다.
---
놀라운 점은 그 효율성입니다. 자체 벤치마크인 ADR-Bench의 전문가 평가에서, 이 모델은 DeepSeek-v3.2나 GLM-4.6 같은 거대 모델들을 압도적인 Elo 점수 차로 따돌렸습니다. 


1. 정답지에서 문제를 훔치다 (Reverse Engineering Strategy)


 - 역설계(Reverse Engineering): 이미 세상에 존재하는 고퀄리티 논문이나 분석 보고서(정답)를 가져옵니다. 그리고 LLM에게 묻습니다. 도대체 어떤 질문을 받았길래 이런 훌륭한 보고서를 쓴 거니?
 - 효과: 이렇게 역으로 생성한 가상의 질문과 원문 보고서를 쌍으로 학습시키면, 모델은 아, 이런 질문이 들어오면 이런 목차와 깊이로 글을 써야 하는구나라는 전문가의 사고 과정(Implicit Planning Logic)을 통째로 흡수하게 됩니다.


2. 축구 선수를 키우는 법: 기초 체력 훈련 (Atomic Mid-training)

이 논문은 SFT(지도 학습) 전에 Mid-training 단계를 둡니다.

 - 원자적 능력(Atomic Capabilities): 축구 경기를 뛰게 하기 전에 패스, 드리블, 체력 훈련을 따로 시키는 것과 같습니다. 모델에게 바로 보고서 써라고 하지 않고, ①계획 짜기, ②정보 찾기, ③반성하기, ④글쓰기라는 4가지 능력을 각각 따로 집중 훈련시킵니다.


3. 채점표가 곧 보상이다 (Rubrics as Rewards)


 - 체크리스트 평가: 연구진은 2023년 이후 데이터를 포함했는가?, 경쟁사의 단점을 분석했는가? 같은 구체적인 채점 기준(Rubrics)을 수십 개 만듭니다.
 - 엄격한 심사위원: 그리고 이 기준을 하나라도 어기면 가차 없이 0점을 주는 Strict Reward Mapping을 도입했습니다. 대충 쓴 보고서에 점수를 주지 않으니, 모델은 살아남기 위해 완벽주의자가 될 수밖에 없습니다.


4. 가성비의 혁명 (High Cost-Efficiency)

이 모든 과정의 결론은 가성비입니다.

 - 성능: OpenAI DeepResearch, Gemini DeepResearch와 같은 1티어 상용 모델들과 대등한 점수(61.42점)를 기록했습니다.
 - 비용: 하지만 추론 비용은 그들의 1/10 수준입니다. 논문은 이를 두고 업계에서 가장 비용 효율적인 딥 리서치 모델이라고 자신 있게 말합니다.


💡 마치며: 누구나 자신만의 대학원생을 가질 수 있다

이 논문은 거대 자본 없이도, 데이터 설계(Data Strategy)만 영리하게 하면 소형 모델로도 전문가급 에이전트를 만들 수 있다는 희망을 줍니다.

저도 이 논문의 철학(작은 모델 + 역설계 데이터)에 영감을 받아, 2.6B라는 초소형 모델(Liquid LFM2)로 논문 관련 연구(Related Work)를 자동 작성해 주는 LFM-Scholar를 만들어 보았습니다. (물론 영감을 받았지만 접근 방식과 목표는 많이 다릅니다.)

👉 LFM-Scholar 구경하기: https://lnkd.in/gF_Pa2yS

단순히 아이디어만 던지면 2.6B 모델이 알아서 관련 논문을 찾고, 읽고, 정리해서 Related Work 섹션 초안을 써줍니다. 작은 모델이 어디까지 똑똑해질 수 있는지, 직접 확인해 보세요.

이제 Deep Research는 빅테크만의 전유물이 아닙니다. 개인들도 자신만의 연구 비서를 가질 시간입니다.
66




