---
id: 38
category: Architecture
title: 최근에 소개한 DroPE가 "위치 정보를 버려라(Drop)"는 뺄셈의 미학이었다면, 오늘 소개할 논문 RePo는 "위치 정보를 재설계(Re-position)하라"는 밀도의 혁신입니다. Sakana AI가 또 한 번 멋진 논문을 공개했습니다.
---
최근에 소개한 DroPE가 "위치 정보를 버려라(Drop)"는 뺄셈의 미학이었다면, 오늘 소개할 논문 RePo는 "위치 정보를 재설계(Re-position)하라"는 밀도의 혁신입니다. Sakana AI가 또 한 번 멋진 논문을 공개했습니다. 

우리가 그동안 LLM에게 "너는 1번, 쟤는 2번..." 하며 기계적으로 나눠주던 번호표가 사실은 모델의 지능을 떨어뜨리고 있었다면 어떨까요?

Sakana AI의 또다른 논문, RePo: Language Models with Context Re-Positioning입니다. 기존 LLM이 겪던 순서의 강박을 깨고, 정보의 밀도를 비약적으로 높인 이 기술을 6가지 핵심 포인트로 정리했습니다.

1. 인지 부하 이론(CLT): 뇌는 순서대로 기억하지 않는다

우리가 복잡한 글을 읽을 때를 떠올려보세요. 문장을 처음부터 끝까지 기계적으로 기억하지 않습니다. 관련된 내용끼리 묶고(Chunking), 불필요한 조사는 흘려버립니다.

논문은 기존의 고정된 위치 인코딩(Fixed Positional Embeddings, 0-1-2...)이 모델에게 "불필요한 인지 부하(Extraneous Cognitive Load)"를 준다고 지적합니다.

정보의 중요도와 상관없이 무조건 선형적으로 처리하게 강제하기 때문입니다. RePo는 이 족쇄를 풉니다. "순서는 중요하지 않아. 내용(Content)이 중요하지."


2. 메커니즘: 정수(Integer)의 감옥을 탈출하다

RePo는 0, 1, 2... 같은 정수 인덱스를 버리고, 학습 가능한 실수(Real-number) 좌표를 사용합니다.

핵심은 f_φ라는 경량화된 모듈입니다. 이 녀석은 토큰의 내용(Hidden State)을 보고 "너랑 쟤랑은 내용이 비슷하니, 물리적으로 멀리 있어도 좌표상으로는 옆에 앉아!"라며 위치를 동적으로 재배치합니다. 이 실수 좌표가 RoPE 수식에 대입되면서 모델은 문맥을 입체적으로 이해하게 됩니다.


3. DroPE vs RePo: 버릴 것인가, 고쳐 쓸 것인가?

두 논문은 같은 문제의식에서 출발했지만, 해결책은 정반대입니다.

 - DroPE (뺄셈): "위치 정보가 편견을 만드니, 눈을 가리고(Drop) 문맥의 흐름만 느껴라." 👉 초장문 확장(Length Extrapolation)에 특화.
 - RePo (재조정): "위치 정보가 멍청하니, 내비게이션(Module)을 달아서 지름길을 찾아라." 👉 복잡한 추론 & 노이즈 제거에 특화.

DroPE가 무한한 길이를 열었다면, RePo는 그 안에서 길을 잃지 않는 법을 제시합니다.


4. 성능: 소음 속의 바늘 찾기 (Robustness to Noise)

RePo의 진가는 "더러운 데이터(Noisy Context)"에서 드러납니다.


즉, "거리는 멀어도 마음은 가깝다"를 수학적으로 구현해 낸 것입니다.


5. 발견: 모델이 스스로 깨우친 하이브리드 전략

가장 흥미로운 점은 모델이 학습한 위치 패턴입니다. 사람의 개입 없이 모델 스스로 상황에 따라 전략을 바꿉니다.

 - Constant 패턴: "여긴 별 내용 없네?" → 위치 값을 모두 상수로 통일 (마치 NoPE 처럼)
 - Monotonic 패턴: "이건 순서가 중요해." → 1, 2, 3 처럼 순차 증가 (RoPE 처럼)
 - Hybrid: 이 둘을 섞어서 사용.

모델은 언제 줄을 서야 하고, 언제 줄을 이탈해야 하는지 스스로 알고 있었습니다.




 - Continual Pre-training: 이미 학습된 모델(OLMo-2 등)에 RePo 모듈만 얹어서 약 500억(50B) 토큰만 더 학습시키면 됩니다.
 - 오버헤드 제로: 파라미터는 단 0.9% 증가하며, 추론 속도 저하는 거의 없습니다.

기존 모델을 스마트한 모델로 개조하는 가장 저렴하고 확실한 튜닝법입니다.


💡 마치며: 질서의 재구성 (Reorganization)

우리는 그동안 컨텍스트 윈도우(Window)의 크기를 늘리는 데만 집착했습니다. 하지만 RePo는 윈도우 안의 질서를 이야기합니다.

RAG 시스템을 구축하다 보면 필연적으로 쓰레기 정보(Noise)가 섞여 들어옵니다. 이때 RePo는 쓰레기는 멀리 보내고, 핵심 정보만 가까이 당겨오는 문맥의 공간 왜곡을 보여줍니다.

만약 DroPE의 무한한 확장성과 RePo의 지능적 재배치 능력이 하나로 합쳐진다면 어떨까요? 그것이야말로 우리가 기대하는 LLM의 기억 방식에 가장 근접한 모습일지도 모르겠습니다.
likelove
21




