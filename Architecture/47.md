---
id: 47
category: Architecture
title: Sakana AI DroPE
---
# Sakana AI: 위치 정보(Positional Embeddings)는 버려라

LLM의 컨텍스트 길이를 늘리는 것은 항상 돈과의 싸움이었습니다. 긴 문맥을 학습시키려면 천문학적인 GPU 비용이 들기 때문이죠. 그런데 Sakana AI와 옥스포드 대학 연구진이 이 상식을 뒤집는 논문을 발표했습니다. "위치 정보(Positional Embeddings)는 학습할 때만 쓰고, 실전에서는 버려라."

제목부터 멋진 논문, **DroPE (Extending the Context of Pretrained LLMs by Dropping Their Positional Embeddings)**입니다. 기존 RoPE Scaling 방식들이 억지로 끼워 맞추느라 놓쳤던 성능을, 단 1%의 비용으로 해결한 이 영리한 뺄셈의 미학을 6가지 포인트로 정리했습니다.

## 1. 비계(Scaffolding) 이론: RoPE는 건물을 짓기 위한 임시 구조물이다

LLM의 표준인 RoPE(Rotary Positional Embeddings)는 모델이 단어의 순서를 배우게 하는 GPS 역할을 합니다. 덕분에 학습 속도가 빠르고 안정적이죠.

하지만 연구진은 RoPE를 건축용 비계(Scaffolding)로 재정의했습니다.

*   **학습 중(공사 중):** 비계가 있어야 인부들이 높이 올라가서 건물을 짓습니다. (RoPE 필수)
*   **추론 중(완공 후):** 건물이 다 지어졌는데 비계를 남겨두면, 오히려 시야를 가리고 확장을 방해합니다.

DroPE는 이 비계를 과감히 철거하는 방법론입니다. 학습 때는 RoPE로 빠르게 배우고, 다 배우면 RoPE를 떼버립니다.

## 2. 구현의 마법: Train, Drop, then Recalibrate

그렇다면 처음부터 위치 정보 없이(NoPE) 학습하면 되지 않을까요? 안타깝게도 그러면 모델이 너무 멍청해져서 학습이 안 됩니다. DroPE는 하이브리드 전략을 씁니다.

1.  **1단계 (Train):** RoPE를 껴서 정상적으로 학습시킵니다. 언어 능력을 마스터합니다.
2.  **2단계 (Drop):** 학습이 끝나면 RoPE를 제거합니다. 모델은 순간적으로 좌표를 잃고 당황합니다.
3.  **3단계 (Recalibrate):** 전체 데이터의 약 0.5%~1%만 보여주며 "눈치(Context)로 순서를 파악해"라고 재활 훈련을 시킵니다.

놀랍게도 이 짧은 재보정만으로 모델은 기존 성능을 95% 이상 회복하면서, 동시에 길이 제한이라는 족쇄에서 풀려납니다.

## 3. 성능: 망원경의 렌즈를 닦다 (vs YaRN)

기존에 우리가 쓰던 YaRN이나 NTK 같은 방식은 긴 문맥을 억지로 구겨 넣는 압축 방식입니다.

*   **YaRN:** 렌즈를 압축해서 멀리 봅니다. 그러다 보니 저주파 신호(의미 정보)가 왜곡되어, 멀리 있는 정보가 흐릿해집니다.
*   **DroPE:** 렌즈 자체를 없애고 자연광으로 봅니다. 신호 왜곡이 없습니다.

실험 결과(NIAH, 바늘 찾기)가 이를 증명합니다.

*   **RoPE + YaRN:** 다중 키 찾기 성공률 0.5% (거의 실패)
*   **DroPE:** 다중 키 찾기 성공률 41.6% (압도적)

## 4. 가성비: 단 50억 토큰이면 충분하다

이 논문이 우리에게 중요한 이유는 가성비입니다. LLaMA나 Qwen 같은 이미 잘 학습된 모델을 가져와서, DroPE 방식으로 바꾸는 데 드는 비용은 충격적으로 적습니다.

*   **SmolLM-360M:** 원본 학습량의 0.8% (50억 토큰) 재학습.
*   **Llama-2-7B:** 원본 학습량의 0.5% (200억 토큰) 재학습.

바닥부터 다시 학습해야 하는 다른 방법론(RoPE++ 등)과 달리, 기존 모델을 적은 비용으로 Long-Context 모델로 개조할 수 있는 가장 현실적인 레시피입니다.

## 5. 미래의 청사진: 꿈의 결합 (MLA + DroPE)

이 논문을 보며 든 생각은 "이걸 DeepSeek의 MLA와 합치면 어떨까?"입니다.

*   **DeepSeek MLA:** 메모리(KV Cache)를 90% 압축하는 기술.
*   **Sakana DroPE:** 길이 제한을 무한대로 푸는 기술.

이 둘이 결합된다면 이론상 무한한 길이를 읽으면서도 메모리는 거의 안 쓰는 궁극의 모델이 탄생합니다. 이는 GPU 자원이 부족한 개인 연구자들이 시도해 볼 만한 가장 가치 있는 End Game 연구 주제일 것입니다.

## 6. 한계: 공짜 점심은 없다 (Engineering Cost)

물론 이 방법이 마법의 만능열쇠는 아닙니다. YaRN처럼 설정 파일 하나만 바꾸면 되는(Plug-and-Play) 방식이 아닙니다.

*   **재보정(Recalibration) 필수:** 어쨌든 GPU를 돌려서 추가 학습을 시켜야 합니다. 데이터 파이프라인을 구축해야 한다는 뜻입니다.
*   **학습 불안정성:** 갑자기 위치 정보를 빼면 모델이 발산할 수 있어, QKNorm 같은 별도의 안정화 장치를 달아줘야 합니다.
*   **추론 튜닝:** 학습 길이보다 10배, 100배 긴 문맥을 처리할 때는 Softmax 온도를 조절하는 추가적인 튜닝 과정이 필요합니다.

---

## 💡 마치며: 뺄셈의 미학

우리는 성능을 높이기 위해 무언가를 자꾸 더하려고만 했습니다. 더 복잡한 수식, 더 많은 파라미터... 하지만 이 논문은 "가장 핵심적인 부품(RoPE)이라도, 때가 되면 버려야 한다"는 뺄셈의 미학을 보여줍니다.

위치 번호라는 강박을 버리고 문맥의 흐름에 몸을 맡길 때, AI는 비로소 한계를 넘어설 수 있었습니다.
