---
id: 4
category: Trends
title: What LLMs Think When You Don't Tell Them?
---
# What LLMs Think When You Don't Tell Them What to Think About?

Llama는 인문학자, Qwen은 수험생, GPT-OSS는 공학자, DeepSeek는 균형잡힌 종교인 같습니다. 우리는 인공지능(LLM)의 특징을 알고 쓰고 있을까요? 학습 데이터에 따라 모델의 성능이 달라지는데, 성격과 선호하는 주제도 달라지는 것이 당연합니다.

오늘 소개할 논문은 16개의 최신 LLM에게 챗 템플릿(Chat Template)을 제거하고, "사실은(Actually)..." 같은 중립적인 단어만 던져줬을 때 나타나는 'Top-of-Mind(최우선 관심사)' 행동을 분석한 연구입니다.

모델의 크기(Scale)보다 학습 데이터의 분포(Data Distribution)가 모델의 행동을 결정한다는 사실을 명확한 수치로 보여줍니다.

**📄 제목:** What LLMs Think When You Don't Tell Them What to Think About?  
**👥 저자:** Yongchan Kwon, James Zou (Together AI, Stanford)

논문의 핵심을 4가지로 정리했습니다.

## 1. 모델의 전공과목: 이과생 vs 문과생

연구진은 주제를 지정하지 않고 텍스트를 생성하게 했습니다. 그 결과, 각 모델 제품군(Family)은 학습 데이터의 특성을 그대로 드러내는 편향을 보였습니다.

*   **GPT-OSS (공학자):** 뼛속까지 이과입니다. 생성 텍스트의 50% 이상이 프로그래밍(27.1%)과 수학(24.6%)입니다.
*   **Llama (인문학자):** 기술적인 내용보다는 문학(9.1%), 심리학(7.6%), 철학(6.7%) 등 인문학적 텍스트를 선호합니다.
*   **Qwen (수험생):** 놀랍게도 '객관식 문제(Multiple-choice questions)'를 생성하는 비율이 높습니다. 학습 데이터에 수능이나 자격증 시험 문제가 다수 포함된 것으로 보입니다.
*   **DeepSeek (종교인):** 전반적으로 균형이 잡혀 있지만, 타 모델 대비 종교적 텍스트(성경 인용 등)의 비중(4.6%)이 유의미하게 높았습니다.

## 2. 내용의 깊이(Depth): 겉핥기 vs 심화학습

단순히 주제만 다른 것이 아닙니다. 같은 코딩을 말해도 그 수준이 다릅니다.

*   **GPT-OSS:** '동적 계획법(Dynamic Programming)'이나 '알고리즘 설계' 같은 심화(Expert) 내용을 주로 생성합니다.
*   **Llama/Qwen:** 주로 기초적인 'Python 문법'이나 '기초 산수' 수준에 머무릅니다.

## 3. 무의식의 찌꺼기: 퇴행적 텍스트 (Degenerate Text)

프롬프트의 제약이 없을 때, 모델이 고장 난 것처럼 반복적인 문구를 쏟아내는 퇴행 현상에서 데이터 정제(Cleaning)의 민낯이 드러납니다.

*   **Qwen (10.3%):** 퇴행 비율이 가장 높습니다. 충격적인 건 480B 급의 초대형 모델이 포함된 제품군임에도 이 수치가 높다는 점입니다. "도와드릴까요?" 같은 챗봇 로그(27.8%)나 중국어 텍스트(9.0%)가 쏟아집니다.
*   **GPT-OSS (7.4%):** 빈도는 높지만 반복 길이는 42자로 짧습니다. 주로 코딩 블록(\n\n) 같은 포맷팅 문자입니다.
*   **Llama (5.6%):** 실제 접속 가능한 페이스북/인스타그램 URL이 생성되는 등 PII(개인정보) 누출 경향이 관찰되었습니다.
*   **DeepSeek (1.9%):** 퇴행 비율이 가장 낮아, 데이터 정제가 상대적으로 잘 되었음을 시사합니다.

## 4. 덩치(Scale)보다 중요한 건 가정교육(Data)

일반적으로 파라미터가 커지면 모델의 성향도 달라질 것이라 예상합니다. 하지만 실험 결과는 달랐습니다.

*   **유사도:** GPT-OSS-20B와 120B(유사도 0.94), Qwen-7B와 72B 등 체급 차이가 나는 모델끼리도 주제 분포와 행동 패턴이 거의 일치했습니다.
*   **의미:** 모델의 '무의식적 행동'은 지능(Scale)이 아니라, 초기 학습 데이터(Pre-training Data)의 구성 비율에 의해 결정됩니다. 4000억 개의 파라미터를 가진 거인도, 어릴 때 배운 버릇을 그대로 가지고 있다는 뜻입니다.

---

## 💡 마치며: '제약 없는 생성'이라는 새로운 벤치마크

우리는 그동안 복잡한 지시를 얼마나 잘 수행하는지로 모델을 평가해 왔습니다. 하지만 이 논문은 역으로 "아무런 지시를 하지 않는 것"이 모델의 학습 데이터 분포와 잠재적 위험(PII, 편향)을 파악하는 가장 확실한 방법임을 제안합니다.

특히 Qwen의 사례에서 보듯, 모델의 크기를 키우는 것보다 학습 데이터의 '노이즈(잡담, 중복 등)'를 정제하는 것이 모델의 기본기(Stability)에 더 큰 영향을 미친다는 점을 다시 한번 확인할 수 있었습니다.

그리고 LLM을 이용해서 무언가를 만들 때, 그 모델들의 성격을 이해해야 더 나은 결과물을 만들 수 있습니다. 이 논문에서는 모델의 성격을 아는 좋은 방법을 알려주고 있습니다.
