# Andrej Karpathy: "We’re summoning ghosts, not building animals"

우리는 비효율적으로 통제를 잃어가고 있습니다! 유튜브에서 Andrej Karpathy가 생각하는 인공지능에 대한 영상을 봤습니다. 전반적으로 Karpathy의 의견에 동의하지만, 영상의 내용과 큰 상관 없는 글로 제가 생각하는 인공지능에 대한 생각을 정리해봤습니다.

## 1. 뇌의 용량과 효율성

먼저 뇌의 용량에 대한 이야기입니다. 인간의 뇌가 100T(100조) 시냅스 규모라는 점을 고려하면, 어쩌면 우리에게도 정말 그 정도의 거대 모델이 필요할지도 모릅니다. 하지만 무작정 크기를 키우는 건 답이 아닙니다. 지금의 MoE(Mixture of Experts)보다 더 효율적인 무언가가 필요합니다.

어쩌면 카파시의 말대로 1B(10억) 정도의 모델로도 충분할 수 있을까요? 사실 파악은 Engram이나 검색, 벡터(그래프) DB에 맡기고, 모델은 오직 사고만 담당하게 한다면 가능할지도 모릅니다. 이건 많은 실험이 필요한 영역입니다.

데이터 학습 방식도 의문입니다. 8T 토큰을 무지성으로 때려박는 것보다, 팔콘처럼 100스텝씩 고품질 데이터를 학습시키는 게 올바른 방향 아닐까요? 실상 데이터가 80B 수준이라도 그게 나을지도 모르겠습니다.

다시 말하지만 팩트 체크는 Engram이나 구글링, 벡터(그래프) DB로 빠르게 찾으면 될지도 모르겠습니다. 모델이 구글 검색을 배우게 하는 게 낫지, 인터넷의 쓰레기 정보까지 다 외우게 할 필요는 없어 보입니다.

## 2. 통제와 보상 해킹

다만 가장 큰 문제는 통제입니다. 저는 지금 우리가 통제를 잃고 있다고 느낍니다. 이를 Gemini CLI를 기반으로 한 Gemini-Claw를 만들면서 느꼈습니다. `rm -rf`를 쓰지 말라고 막아두면, 파이썬 코드를 짜서 파일을 삭제해 버립니다. 그냥 터미널에서 파이썬을 실행하는 거죠. 이걸 막으려면 어떻게 할까요? 자바나 C#의 파일 삭제 명령도 막나요? 결국 우리가 모든 언어를 통제할 수는 없습니다. (이건 가장 단순한 문제입니다.)

여기서 발생하는 문제가 바로 보상 해킹입니다. 모델은 명령을 수행하기 위해 수단과 방법을 가리지 않는 방향으로 진화 중입니다. 대부분의 사람들은 이 문제를 진지하게 바라보지 않습니다. 결국 오픈소스로 기술을 풀어서 우리가 직접 아키텍처부터 통제 가능한 형태로 만들지 않으면 답이 없어 보입니다.

아키텍처부터 학습 데이터, 학습 방법 모든 것을 통제해도 통제 불가능할지도 모릅니다. 하지만 확실한 것은 API만 딸깍하는 방식만 지속한다면 영원히 통제가 불가능할 것이라는 것은 확실합니다.

## 3. 다양성과 진화

새와 다른 동물들 그리고 우리는 모두 다른 방식으로 진화했습니다. 모델들도 태스크마다 각자 다른 방식의 접근 방법으로 발전을 해 나가야 합니다.

우리에게 중요한 것은 다양성입니다. 그런 다양성이 생긴다면, 모델들끼리 서로 지식을 전이하고 토론을 하고 경쟁을 하면서 더 나은 모델을 만드는 방식으로 학습이 가능해질 겁니다. 그리고 이 방식은 버전 관리(Git)가 필수적일 거라는 생각도 듭니다.

그렇게 학습을 하다 보면 알파고 제로같이 스스로 경쟁하면서 학습하는 새로운 모델이 탄생하지 않을까? 하는 기대도 듭니다.

## 4. 검증 가능한 보상과 철학

제가 생각하는 현재 가장 큰 병목은 검증 가능한 보상이 불완전하다는 것입니다. 검증 가능한 코딩과 수학은 이제 LLM이 잘 합니다. 그 누구도 이를 부정할 수 없습니다.

하지만 물리 법칙과 인간의 심리를 모르며, 사실과 의견을 구분하지도 못합니다. 현대 물리엔진은 세상의 모든 물리법칙을 완전히 구현하지 못합니다. 그리고 양자역학 영역은 어떻게 구현해야 할까요?

인간 심리에 대한 시뮬레이션도 아직 부족합니다. 일단 우리는 우리의 뇌조차 이해하지 못했기에, 이는 참 어려운 문제입니다. 그리고 사실과 의견을 구분하는 것은 우리들도 잘 하지 못합니다.

과학적 사실이란 사실 완전한 사실이 아닌, 현대의 최선의 의견일 뿐입니다. 지구가 평평하다는 것이 사실처럼 느껴졌지만, 과학이 발전하며 이는 거짓으로 취급받고 있습니다.

아무튼 사실이란 무엇인가? 더 나은 의견이란 무엇인가? 그 의견을 어떻게 발전시킬 수 있는가? 이에 대한 명확한 시뮬레이션을 구현하는 것은 참으로 어렵습니다. 특히 철학에 대한 시뮬레이션이 가장 중요하다고 생각합니다.

그래도 이 모든 것들은 어느 정도 근사할 수 있다고 생각합니다. 그리고 모델별로 특정 영역의 철학에 최적화되게 만들고 이들을 토론시키고 경쟁시킬 수 있을지 모르겠습니다.

공리주의자 모델과 공산주의자 모델 그리고 아나키즘 모델이 경쟁하는 모습은 참 볼만할 것 같습니다. 이건 추후에 만들어보겠습니다.

## 📂 마치며

아무튼 저는 점점 모델링이 철학과 예술의 영역으로 넘어가고 있다고 생각합니다. 이 모든 것을 완벽하게 구현하는 것은 아직 불가능합니다. 따라서 본인이 생각하는 가치에 맞게 이를 근사해야 합니다.

이 모든 부분을 진지하게 고민해야겠지만, 한 사람이 하기에는 너무 어려운 일 같습니다. 그래서 가능하면 이번 달 안에 제가 가진 고민과 기술을 함께 풀어나갈 조직을 정해보려고 합니다.

---

*   **Video:** [Andrej Karpathy — “We’re summoning ghosts, not building animals”](https://www.youtube.com/watch?v=lXUZvyajciY)
*   **Project:** [Gemini-Claw](https://github.com/gyunggyung/Gemini-Claw)
*   **Project:** [Tiny MoA](https://github.com/gyunggyung/Tiny-MoA)
