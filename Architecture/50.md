---
id: 50
category: Architecture
title: Nemotron-3-Nano-30B-A3B은 Qwen3-30B-A3B보다 3.3배, GPT-OSS-20B보다 2.2배 더 빠릅니다. 단순히 속도만 빠른 게 아닙니다. Qwen3 대비 지시 이행(IFBench) 성능은 40% 이상 뛰어나며, 수학(AIME), 에이전트(TauBench) 성능에서도 더 뛰어납니다. 특히 Mamba-2 하이브리드 구조 덕분에, CPU만으로 초당 20토큰(20 t/s) 이상을 뽑아냅니다. 거기다 컨텍스트 길이는 무려 100만 토큰(1M)입니다.
---
Nemotron-3-Nano-30B-A3B은 Qwen3-30B-A3B보다 3.3배, GPT-OSS-20B보다 2.2배 더 빠릅니다. 단순히 속도만 빠른 게 아닙니다. Qwen3 대비 지시 이행(IFBench) 성능은 40% 이상 뛰어나며, 수학(AIME), 에이전트(TauBench) 성능에서도 더 뛰어납니다. 특히 Mamba-2 하이브리드 구조 덕분에, CPU만으로 초당 20토큰(20 t/s) 이상을 뽑아냅니다. 거기다 컨텍스트 길이는 무려 100만 토큰(1M)입니다.

심지어 모델 웨이트, 25T(25조) 토큰 분량의 학습 데이터 레시피, 리워드 모델, 훈련 코드까지 싹 다 공개했습니다. Nemotron-3-Nano-30B-A3B은 저도 링크드인 포스팅에서 가끔 다룬 모델입니다. 이제 다양한 자료를 보고, 이 모델의 핵심 디테일 4가지를 정리했습니다.

1. 아키텍처 심층 분석: 맘바(Mamba) 샌드위치의 엔지니어링 미학

이 모델이 Qwen3보다 3.3배 빠르면서도 성능을 유지하는 비결은, 트랜스포머의 무거움을 덜어내기 위해 설계된 Interleaved Hybrid(교차 혼합) 구조에 있습니다.

단순히 섞은 것이 아닙니다. NVIDIA는 총 52개의 레이어를 마치 정밀한 기계 부품처럼 배치하여 기억(Memory)과 추론(Reasoning)의 효율을 극한으로 튜닝했습니다.

(1) 88 대 12의 황금비 (Layers Distribution)
전체 52개 레이어는 단 하나의 목표, KV-Cache 병목 제거를 위해 배분되었습니다.

 - Mamba-2 레이어 (46개, 약 88%): 모델의 몸통입니다. 문맥의 흐름을 O(N) 선형 시간으로 처리합니다. 기존 트랜스포머와 달리 과거의 모든 토큰을 들고 다닐 필요 없이, 압축된 상태(State)만 넘기면 되므로 메모리를 거의 먹지 않습니다.
 - Attention 레이어 (6개, 약 12%): 모델의 눈입니다. Mamba가 놓칠 수 있는 디테일을 잡기 위해, 전체 문맥을 다시 한번 훑어보는(Recall) 역할을 합니다. 단 6개만 배치함으로써, 100만 토큰(1M)을 넣어도 메모리가 터지지 않게 막았습니다.

(2) 구조의 미학: 매크로 블록 & 극한의 효율
논문의 Figure 2는 단순한 나열이 아닌, 치밀하게 계산된 리듬을 보여줍니다. 

 - 배치 패턴 (Rhythm): [Mamba x3 → Attn x1] 패턴을 5번 반복해 연산 속도와 기억력의 균형을 잡고, 중반부엔 Mamba만 연속 배치해 가속을 극대화했습니다. 마지막은 Attention으로 문맥을 최종 정렬합니다. 

 - 극한의 다이어트 (Spec):
 - GQA 32:2: KV 헤드를 단 2개로 줄였습니다. 100만 토큰을 처리할 때 KV-Cache 메모리가 터지지 않는 결정적 이유입니다. 

 - Fine-grained MoE: 128명의 전문가 중, 질문에 맞는 6명(Routed)과 상시 대기조 2명(Shared)만 깨웁니다. 30B의 뇌를 3B의 무게로 움직이는 비결입니다. 

단 6개의 Attention으로 정확도를, 46개의 Mamba로 100만 토큰의 효율을 확보한 이 구조는, KV-Cache 폭발 없이 노트북에서도 30B 모델이 빠른 물리적 근거가 됩니다.


2. 학습의 정수: 찍지 마, 풀어서 맞춰 (RLVR)

DeepSeek-R1이 쏘아 올린 사고(Reasoning) 모델 트렌드를 완벽하게 흡수했습니다. 핵심은 RLVR (Reinforcement Learning from Verifiable Rewards)입니다.

 - 검증 가능한 보상: 에세이 채점 같은 모호한 피드백이 아닙니다. 수학 답이 맞았는지, 코드가 컴파일되는지(True/False) 명확한 신호로만 강화학습을 돌렸습니다.
 - 멀티 환경 동시 학습: 보통 수학을 가르치면 코딩을 까먹는데(Catastrophic Forgetting), 이 모델은 수학, 코딩, 지시 이행 등 모든 환경을 동시에 띄워놓고 학습했습니다.
 - Curriculum Learning: 처음엔 쉬운 문제로 자신감을 주고, 점차 어려운 문제(Low Pass Rate)를 던져주는 방식으로 학습 효율을 극대화했습니다.

그 결과, AIME(수학) 벤치마크에서 89.06% (도구 사용 시 99.2%)를 기록하며 동급 모델들을 압도했습니다.


3. 데이터의 민주화: 낚싯대까지 다 줍니다

가장 멋진 건 데이터셋 공개입니다. 모델 껍데기만 던져준 게 아닙니다.

 - Nemotron-CC: Common Crawl을 정제한 방대한 데이터.
 - CC-Code & Math: 수식과 코드가 포함된 고품질 데이터.
 - GenRM: 심지어 학습에 쓴 보상 모델(Reward Model)까지 공개했습니다.

데이터가 없어서 LLM 못 만든다는 핑계는 이제 안 통하게 되었습니다. NVIDIA가 25조(25T) 토큰 분량의 정제 노하우를 세상에 뿌려버렸으니까요.


4. 로컬 구동: CPU 유저들의 구세주


보통 30B 모델을 CPU로 돌리면 한 단어 나오는데 세월아 네월아 걸리죠(0.5 t/s). 하지만 Nemotron-3-Nano는 시스템 램(RAM)만 32GB 이상이라면, CPU만으로 초당 20토큰(20 t/s) 이상의 속도를 뽑아냅니다. 사람이 읽는 속도보다 빠릅니다.

NVIDIA는 여기서도 디테일을 챙겼습니다. Selective Quantization(선택적 양자화)을 통해, 지능에 핵심적인 Attention 레이어는 원본(BF16)을 유지하고 나머지 덜 중요한 부분만 압축(FP8)했습니다. 덕분에 성능 저하 없이 로컬에서 쾌적하게 돌아갑니다.


💡 마치며




likelove
39




