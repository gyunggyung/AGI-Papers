---
id: 25
category: Projects
title: 요즘 화제인 Clawdbot은 정말 대단해 보입니다. 제가 만들려는 로컬 전용 AI의 끝판왕 느낌이 납니다. 하지만 진짜 작은 모델들로 진짜 100% 로컬에서 작동하는 것은 아닙니다. 모델을 쓰는데 API 없이 오직 CPU 환경에서, 더 나아가서 모바일에서도 직접 돌아가는 서비스가 필요하다고 생각합니다.
---
요즘 화제인 Clawdbot은 정말 대단해 보입니다. 제가 만들려는 로컬 전용 AI의 끝판왕 느낌이 납니다. 하지만 진짜 작은 모델들로 진짜 100% 로컬에서 작동하는 것은 아닙니다. 모델을 쓰는데 API 없이 오직 CPU 환경에서, 더 나아가서 모바일에서도 직접 돌아가는 서비스가 필요하다고 생각합니다. 

그래서 제 Tiny MoA는 조금 다른 길을 갑니다. "진짜 내 노트북(윈도우 i5, RAM 16G) CPU에서 돌아가는가?"에 집중했습니다. 추후에 기능을 다 만들면, 앱으로 만들어서 모바일에서 작동하는 모습도 보여드리겠습니다.


첨부 파일로 올린 데모에서 보여주는 모습을 정리하면, 

1. 딥마인드와 앤트로픽의 최신 뉴스를 찾습니다. 딥마인드의 뉴스와 앤트로픽의 뉴스를 따로 DuckDuckGo를 써서 찾고, 해당 내용들을 정리해서 알려줍니다. 그리고 뉴스 링크를 클릭하면 실제 뉴스로 들어갑니다. 인공지능이 헛소리를 하는 것이 아닌, 실제 뉴스 기사의 URL를 제공하니 사용자가 직접 내용을 확인해볼 수 있습니다. 

2. 서울, 도쿄, 런던의 날씨를 찾습니다. 3개 도시의 날씨를 찾는 명령을 분해해서, wttr.in으로 하나하나 날씨를 찾고, 찾은 내용들을 알려줍니다.

3. 마지막으로 Attention Is All You Need 논문 일부 PDF 파일을 읽어서 요약을 해줍니다. 먼저 PDF 파일을 Docling으로 LM이 읽을 수 있게 Markdown 형식으로 만들고, 모델이 읽기 쉽게 500자 단위로 나눠서 임베딩을 합니다. ChromaDB로 저장하고, RAG 과정으로 필요한 정보를 기반으로 답변을 해줍니다.

현재 구조는 1.2B 모델(Liquid AI)이 팀장 역할을 맡아 계획을 짜고, 90M, 600M 짜리 초소형 Technology Innovation Institute의 Falcon 모델들이 손과 발이 되어 도구를 쓰고 코드를 짜는 구조입니다. 

지금 당장은 그렇고 Maxime Labonne님의 조언을 받아서 추후에 Liquid Nanos 모델들도 잘 섞어서 써보려고 합니다. 동시에 Pau Labarta Bajo님이 만든 여러 LFM 에이전트들도 넣어서 써볼까 합니다. 

터미널 화면에서 이 작은 녀석들이 서로 일을 주고받으며 결과를 만들어내는 걸 보면 꽤 기특합니다. 물론 대형 모델만큼 유려하진 않지만, API 비용 0원에 램 2GB 안으로 내 컴퓨터 안에서 열심히 데이터를 퍼 나르는 걸 보면 로컬 에이전트만의 매력이 있습니다.


GitHub: https://lnkd.in/gmY8afKq

재생
남은 시간 
0:53
1x

재생 속도


전체화면 설정
likesupportlove
100




