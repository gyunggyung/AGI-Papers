---
id: 101
category: Architecture
title: Titans: Learning to Memorize at Test Time
---
Titans: Learning to Memorize at Test Time

최근 딥러닝 분야에서 Titans는 Transformer의 한계를 넘어설 가능성을 보여주며, 주목받는 새로운 메모리 중심 아키텍처를 제시하고 있습니다. 기존 Transformer의 짧은 컨텍스트 창 한계를 극복하고, 기억 능력을 강화한 Titans는 언어 모델링, 상식 추론, 시간 시계열 예측, DNA 모델링 등에서 탁월한 성능을 보여줍니다. Titans는 다음과 같은 세 가지 핵심 요소를 기반으로 설계되었습니다.

1. 메모리 아키텍처의 혁신

Titans는 짧은 기간의 데이터를 처리하는 단기 메모리, 오래된 정보를 저장하는 장기 메모리, 태스크 관련 메타 정보를 보유하는 지속적 메모리라는 세 가지 구성 요소로 나뉩니다. 이 세 가지 메모리는 독립적으로 작동하면서도 상호보완적으로 학습합니다.

주요 특징:

놀라움 지표(Surprise Metric): 입력 데이터의 변화량(gradient)을 기반으로 중요한 정보를 강조하여 기억에 저장합니다.

적응형 망각 메커니즘: 필요 없는 정보는 동적으로 삭제해 메모리 용량을 최적화합니다.

빠른 병렬 학습: TPU와 GPU에서 효과적으로 병렬화되도록 설계되었습니다.

2. 아키텍처 설계의 다양성

Titans는 메모리를 효율적으로 통합하기 위해 다음과 같은 세 가지 변형 모델을 제공합니다.

MAC (Memory as a Context): 과거 데이터를 컨텍스트로 병합하여 학습에 활용.

MAG (Memory as a Gate): 메모리와 입력 데이터를 게이팅 메커니즘으로 결합.

MAL (Memory as a Layer): 메모리를 네트워크의 독립적인 레이어로 사용.

3. 성능 비교

Titans는 기존 모델과 비교하여 성능 및 확장성 측면에서 뛰어난 결과를 보였습니다.

언어 모델링 및 상식 추론: Titans는 Transformer++, Mamba, DeltaNet을 포함한 최신 모델 대비 평균 2~5% 높은 정확도를 기록했습니다.

‘Needle in Haystack’ 테스트: 길이가 2M 이상의 매우 긴 시퀀스에서도 Titans는 Mamba2, DeltaNet 대비 15% 이상 높은 정보 검색 성공률을 보였습니다.

시간 시계열 및 DNA 예측: Titans는 TimesNet 및 PatchTST와 비교해 평균적으로 MSE를 10~20% 개선하며 정밀한 예측 성능을 입증했습니다.

결론

Titans는 기존 Transformer와 RNN 기반 모델의 단점을 극복하고 효율적인 메모리 관리와 장기적 추론 능력을 통해 차세대 딥러닝 모델로서의 가능성을 제시합니다. 특히, 다양한 데이터 길이와 복잡한 추론 태스크에서의 성능은 Titans가 실제 환경에서 큰 영향을 미칠 수 있음을 시사합니다.

앞으로 Titans가 더 복잡한 태스크와 실전 응용에서 어떻게 사용될지 기대됩니다.
