---
id: 10
category: RAG
title: RAG & Agent Memory 4선
---
RAG & Agent Memory 4선

AG의 한계를 부수는 4개의 최신 논문들을 소개합니다. 

Beyond Naive RAG:

1. GraphSearch (Agentic Deep Search)


여기에 텍스트의 디테일(Semantic)과 그래프의 연결성(Relational)을 동시에 보는 '이중 채널(Dual-Channel)' 전략을 씁니다.

 - 압도적인 추론 능력: MuSiQue 벤치마크(복잡한 질문)에서 기존 LightRAG와 결합했을 때, 정답 포함률(SubEM)이 35.00%에서 51.00%로 수직 상승했습니다.

 - SOTA 갱신: 2WikiMultiHopQA 데이터셋에서는 88.67점의 퀄리티 점수(A-Score)를 기록하며, 기존의 모든 베이스라인을 제쳤습니다.

 - 플러그 앤 플레이: 기존 RAG 시스템에 이 에이전트 워크플로우만 끼워 넣어도 성능이 오릅니다.


2. S-RAG (Structured RAG)
"모든 호텔 중 평점이 가장 높은 곳의 예약 가능 여부는?" 이런 질문, 벡터 DB는 절대 못 풉니다. 흩어진 정보를 모아서 계산(Aggregation)해야 하니까요.


 - 집계형 질문의 학살자: HOTELS 데이터셋에서 기존 VectorRAG의 정답 재현율(Recall)은 0.352에 불과했습니다. S-RAG(GoldSchema)는? 0.845입니다. 비교가 안 됩니다.

 - 금융 데이터 정복: FinanceBench의 집계형 질문에서도 0.750의 재현율을 기록하며, OpenAI의 최신 에이전트(0.500)조차 압도했습니다.


숫자를 다루거나 통계를 내야 한다면, 벡터는 답이 아닙니다. 구조화가 답입니다.

3. xMemory (Beyond RAG for Agent Memory)
에이전트와의 긴 대화를 RAG로 저장한다? 중복된 쓰레기 데이터만 쌓입니다. 에이전트 메모리는 거대한 위키피디아가 아니라, 시간의 흐름이 있는 '스트림'이기 때문입니다.


 - 토큰 효율성 혁명: LoCoMo 벤치마크에서 기존 RAG 대비 쿼리당 토큰 사용량을 6,613개에서 4,711개로 약 29%나 줄였습니다. 돈 아껴주는 기술입니다.

 - 성능 향상: 그러면서도 F1 점수는 36.42에서 43.98로 올랐습니다. 더 적게 읽고 더 정확하게 대답합니다.

 - 동적 구조조정: 메모리가 쌓이면 알아서 합치고(Merge) 쪼개며(Split) 최적의 구조를 유지합니다.

이것이 '뇌'를 가진 에이전트의 기억법입니다.

4. Graph-based Agent Memory Survey
이 모든 흐름을 관통하는 하나의 키워드는 결국 그래프(Graph)입니다.


 - 구조적 기억: 단순한 Key-Value가 아니라, 지식 그래프(KG)나 하이퍼그래프를 통해 인과관계와 계층 구조를 저장합니다.

 - 자기 진화(Self-Evolving): 쓰면 쓸수록 메모리의 구조가 스스로 최적화되고 강화됩니다.

결국 2026년의 에이전트는 로그를 쌓는 게 아니라, 경험을 구조화하여 자신의 '세계관'을 구축해야 합니다.

💡 마치며
RAG는 죽지 않았습니다. 다만, 벡터 유사도에만 의존하던 '순진한(Naive) RAG'의 시대가 끝났을 뿐입니다.

에이전트가 진짜 비서처럼 일하려면, GraphSearch처럼 깊게 고민하고, S-RAG처럼 데이터를 구조화하며, xMemory처럼 효율적으로 기억해야 합니다. 

저는 이 4가지 논문이 제시하는 방향성, 즉 "구조화된 연결(Structured Connection)"이 2026년 에이전트 시장의 승패를 가를 것이라 생각합니다.
likelove
60




