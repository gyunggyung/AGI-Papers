---
id: 106
category: Agents
title: AgentArcEval: Architecture Evaluation
---
# AgentArcEval: 에이전트 아키텍처, 점수 매겨드립니다

> **"LLM 에이전트는 일반 소프트웨어와 다르다. 자율성과 비결정성을 고려한 새로운 평가 프레임워크."**

## 1. 문제

에이전트는 매번 다른 답을 내놓고(비결정성), 스스로 행동합니다(자율성). 기존의 소프트웨어 평가 방법으로는 이들을 제대로 검증할 수 없습니다.

## 2. AgentArcEval 프레임워크

*   **목표 중심**: 기능이 아니라 '목표 달성도'를 평가합니다.
*   **가드레일**: 윤리적, 법적 요구사항(AI Governance)을 아키텍처에 녹여냅니다.
*   **시나리오 카탈로그**: 에이전트가 자주 겪는 11가지 상황을 미리 정의해 테스트합니다.

## 3. 사례 연구 (Luna)

실제 세금 코파일럿 'Luna'에 적용하여, 데이터 업데이트 주기를 실시간으로 바꾸고 법률 근거 추적 기능을 추가하는 등 아키텍처를 개선했습니다.

## 4. 결론

에이전트 시스템을 상용화하려면 '잘 돌아가는지'를 넘어 '믿을 수 있는지'를 증명해야 합니다. AgentArcEval은 그 기준점을 제시합니다.
