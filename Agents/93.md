---
id: 93
category: Agents
title: Chain-of-Draft(CoD)
---
# Chain-of-Draft(CoD)

> **CoT의 장점을 유지하면서 토큰 사용량과 계산 비용을 줄이며, 더 빠른 응답을 가능하게 하는 획기적인 접근법.**

## 1. 논문 개요

*   **문제 제기:** 기존 Chain-of-Thought (CoT) 방식은 다단계 추론을 가능하게 하지만, 과도한 토큰 사용과 연산 지연을 초래함.
*   **핵심 기여:** 새로운 프롬프팅 방식인 **Chain-of-Draft (CoD)** 제안 → 필수적인 정보만 간결하게 작성하여 성능을 유지하면서도 토큰 사용량과 계산 비용을 대폭 절감.
*   **주요 성과:**
    *   GSM8K 산술 추론 테스트에서 토큰 사용량 **80% 감소**, 추론 속도 **76.2% 향상**.
    *   CoT와 유사하거나 더 높은 정확도를 유지하면서도 더 빠르게 계산 가능.
*   **핵심 아이디어:** 인간이 복잡한 문제를 해결할 때, 세부 과정 전체를 서술하지 않고 핵심 개념만 요약하는 방식을 LLM에 적용.

---

## 2. 기존 연구 및 한계

*   **CoT (Chain-of-Thought):** LLM이 단계별 논리적 사고를 수행하도록 유도하는 기법으로, 정확도 향상을 입증했지만 과도한 토큰 사용과 계산 비용 문제 존재.
*   **기타 개선 접근법:**
    *   **ReAct (Reasoning + Acting):** LLM이 외부 도구와 상호작용하도록 함.
    *   **Self-Consistency CoT:** 여러 CoT 경로를 탐색 후 다수결 방식으로 정답을 결정.
    *   **Skeleton-of-Thought (SoT):** 답변의 초안을 먼저 생성한 후 병렬적으로 검증하는 방식.
    *   **Coconut:** 자연어 대신 연속적 벡터 공간에서 추론 수행하여 속도 향상.
*   **한계점:** 기존 접근법들은 토큰 사용을 줄이는 데 집중하지 않거나, 정확도가 감소하거나, 추가적인 LLM 호출이 필요하여 지연 발생.

---

## 3. Chain-of-Draft (CoD) 방법론

*   **핵심 원칙:** 각 추론 단계를 최대한 간결하게 요약하여 계산량과 토큰 사용을 줄임.

### 기존 방식과 비교

| 구분 | 설명 |
| :--- | :--- |
| **기존 CoT 방식** | 모든 추론 단계를 세부적으로 설명 (冗長함). |
| **CoD 방식** | 필수적인 연산 과정만 포함하여 간결한 답변 제공. |

### 프롬프트 예시

#### 1) Standard Prompting (직접 답변)
> **Q:** Jason은 사탕 20개를 가지고 있었다. Denny에게 몇 개를 주었는지 모르지만, 이제 12개가 남아있다. Denny에게 몇 개를 줬는가?  
> **A:** 8

*   **장점:** 빠른 응답
*   **단점:** 중간 논리를 설명하지 않아 복잡한 문제에서는 오류 가능성이 높음.

#### 2) Chain-of-Thought (CoT) Prompting
> **Q:** Jason은 사탕 20개를 가지고 있었다. Denny에게 몇 개를 주었는지 모르지만, 이제 12개가 남아있다. Denny에게 몇 개를 줬는가?  
> **A:** 다음 단계별로 생각해보겠습니다.  
> 1. Jason은 처음에 20개의 사탕을 가짐.  
> 2. 몇 개를 Denny에게 준 후, 12개가 남음.  
> 3. 잃어버린 사탕 개수를 계산하려면: 초기 개수 - 남은 개수.  
> 4. 수식: 20 - 12 = 8.  
> Jason은 8개의 사탕을 Denny에게 주었다.

*   **장점:** 단계별 설명으로 신뢰도 향상.
*   **단점:** 불필요한 서술이 많아 토큰 사용량 증가 → 지연 발생.

#### 3) Chain-of-Draft (CoD) Prompting
> **Q:** Jason은 사탕 20개를 가지고 있었다. Denny에게 몇 개를 주었는지 모르지만, 이제 12개가 남아있다. Denny에게 몇 개를 줬는가?  
> **A:** 20 - x = 12 → x = 8 #### 8

*   **장점:** 최소한의 정보로 계산 과정 유지, 토큰 사용량 **80% 감소**.
*   **단점:** 사람이 직접 해석해야 할 수도 있음.

---

## 4. 실험 결과

### GSM8K (산술 추론)
*   **토큰 사용량:** CoT 대비 **80% 감소**
*   **속도 향상:** GPT-4o에서 76.2%, Claude 3.5 Sonnet에서 48.4% 지연 단축
*   **정확도:** CoT(95.4%) → CoD(91.1%)로 미세한 감소

### Common Sense Reasoning (BIG-Bench)
*   **토큰 사용량:** **92.4% 감소** (Claude 3.5 Sonnet, 스포츠 이해 과제)
*   **정확도:** CoD가 CoT보다 더 높음

---

## 5. 결론 및 향후 연구 방향

CoD는 CoT와 유사한 정확도를 유지하면서도 훨씬 적은 토큰을 사용하여 비용 절감 및 속도 향상을 달성함.

### 적용 가능성
*   실시간 LLM 서비스 (예: 챗봇, 금융 분석)
*   API 기반 모델의 비용 절감
*   긴 답변이 필요 없는 애플리케이션

### 향후 연구 방향
*   **CoD + Multi-Pass Verification:** 짧게 생성된 답을 검증하는 방식.
*   **CoD + Adaptive Parallel Reasoning:** 병렬 추론을 활용하여 더 빠른 응답 생성.
*   **CoD 기반의 새로운 훈련 기법:** LLM을 더 효율적으로 학습하는 새로운 전략.

---

## 6. 총평

*   **혁신성:** CoT의 비효율성을 해결하는 실용적인 대안.
*   **효율성:** 80% 토큰 절약 → 비용 절감, 속도 향상.
*   **적용성:** 실시간 LLM 응용에 적합.
*   **한계점:** 일부 문제에서는 추가적인 검증 과정이 필요할 수 있음.
